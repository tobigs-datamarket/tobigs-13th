{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ''' ? ''' 이 있는 부분을 채워주시면 됩니다\n",
    "\n",
    "나는 내 스타일로 하겠다 하시면 그냥 구현 하셔도 됩니다!!\n",
    "\n",
    "참고하셔야 하는 함수들은 링크 달아드렸으니 들어가서 확인해보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) PCA의 과정을 한번 차근차근 밟아 볼거에요 잘 따라 오세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "#   기본 모듈들을 불러와 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = [95, 91, 66, 94, 68, 63, 12, 73, 93, 51, 13, 70, 63, 63, 97, 56, 67, 96, 75, 6]\n",
    "x2 = [56, 27, 25, 1, 9, 80, 92, 69, 6, 25, 83, 82, 54, 97, 66, 93, 76, 59, 94, 9]\n",
    "x3 = [57, 34, 9, 79, 4, 77, 100, 42, 6, 96, 61, 66, 9, 25, 84, 46, 16, 63, 53, 30]\n",
    "\n",
    "#   설명변수 x1, x2, x3의 값이 이렇게 있네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack((x1,x2,x3),axis=0)\n",
    "\n",
    "#   설명변수들을 하나의 행렬로 만들어 줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X.T,columns=['x1','x2','x3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>56</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>93</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>25</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>83</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>70</td>\n",
       "      <td>82</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>54</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "      <td>93</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>67</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>96</td>\n",
       "      <td>59</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>75</td>\n",
       "      <td>94</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1  x2   x3\n",
       "0   95  56   57\n",
       "1   91  27   34\n",
       "2   66  25    9\n",
       "3   94   1   79\n",
       "4   68   9    4\n",
       "5   63  80   77\n",
       "6   12  92  100\n",
       "7   73  69   42\n",
       "8   93   6    6\n",
       "9   51  25   96\n",
       "10  13  83   61\n",
       "11  70  82   66\n",
       "12  63  54    9\n",
       "13  63  97   25\n",
       "14  97  66   84\n",
       "15  56  93   46\n",
       "16  67  76   16\n",
       "17  96  59   63\n",
       "18  75  94   53\n",
       "19   6   9   30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-1) 먼저 PCA를 시작하기 전에 항상!!!!!! 데이터를 scaling 해주어야 해요\n",
    "\n",
    "https://datascienceschool.net/view-notebook/f43be7d6515b48c0beb909826993c856/ 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #스케일링\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X) #fit메서드로 데이터 변환을 학습, transform매서드로 실제 데이터의 스케일 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.02614175,  0.30684189],\n",
       "       [ 0.93801686, -0.86575334, -0.46445467],\n",
       "       [ 0.01477192, -0.92726334, -1.30282049],\n",
       "       [ 1.04880625, -1.66538341,  1.04460382],\n",
       "       [ 0.08863151, -1.41934339, -1.47049366],\n",
       "       [-0.09601747,  0.76426183,  0.97753455],\n",
       "       [-1.97943714,  1.13332186,  1.74883111],\n",
       "       [ 0.2732805 ,  0.42595679, -0.1961776 ],\n",
       "       [ 1.01187645, -1.5116084 , -1.40342439],\n",
       "       [-0.53917504, -0.92726334,  1.61469258],\n",
       "       [-1.94250735,  0.85652683,  0.44098042],\n",
       "       [ 0.16249111,  0.82577183,  0.60865359],\n",
       "       [-0.09601747, -0.03536825, -1.30282049],\n",
       "       [-0.09601747,  1.28709688, -0.76626636],\n",
       "       [ 1.15959564,  0.33369178,  1.21227698],\n",
       "       [-0.35452606,  1.16407687, -0.06203907],\n",
       "       [ 0.05170172,  0.64124181, -1.06807806],\n",
       "       [ 1.12266584,  0.11840676,  0.50804969],\n",
       "       [ 0.3471401 ,  1.19483187,  0.17270336],\n",
       "       [-2.20101593, -1.41934339, -0.5985932 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_std.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.08573604,  0.93801686,  0.01477192,  1.04880625,  0.08863151,\n",
       "        -0.09601747, -1.97943714,  0.2732805 ,  1.01187645, -0.53917504,\n",
       "        -1.94250735,  0.16249111, -0.09601747, -0.09601747,  1.15959564,\n",
       "        -0.35452606,  0.05170172,  1.12266584,  0.3471401 , -2.20101593],\n",
       "       [ 0.02614175, -0.86575334, -0.92726334, -1.66538341, -1.41934339,\n",
       "         0.76426183,  1.13332186,  0.42595679, -1.5116084 , -0.92726334,\n",
       "         0.85652683,  0.82577183, -0.03536825,  1.28709688,  0.33369178,\n",
       "         1.16407687,  0.64124181,  0.11840676,  1.19483187, -1.41934339],\n",
       "       [ 0.30684189, -0.46445467, -1.30282049,  1.04460382, -1.47049366,\n",
       "         0.97753455,  1.74883111, -0.1961776 , -1.40342439,  1.61469258,\n",
       "         0.44098042,  0.60865359, -1.30282049, -0.76626636,  1.21227698,\n",
       "        -0.06203907, -1.06807806,  0.50804969,  0.17270336, -0.5985932 ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-2) 자 그럼 공분산 행렬을 구해볼게요\\\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.cov.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cov_matrix = np.cov(features) #공분산구하는 np.cov사용-> 주어진값 바탕으로 공분산 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-3) 이제 고유값과 고유벡터를 구해볼게요\n",
    "\n",
    "방법은 실습코드에 있어요!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.48756162, 0.94435407, 0.72597904]),\n",
       " array([[ 0.47018528, -0.85137353, -0.23257022],\n",
       "        [-0.64960236, -0.15545725, -0.74421087],\n",
       "        [-0.59744671, -0.50099516,  0.62614797]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin.eig(cov_matrix) #eigenvalue, eigenvector 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues = lin.eig(cov_matrix)[0]\n",
    "eigenvectors = lin.eig(cov_matrix)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.48756162 0.94435407 0.72597904]\n",
      "[[ 0.47018528 -0.85137353 -0.23257022]\n",
      " [-0.64960236 -0.15545725 -0.74421087]\n",
      " [-0.59744671 -0.50099516  0.62614797]]\n"
     ]
    }
   ],
   "source": [
    "print(eigenvalues)\n",
    "print(eigenvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.zeros((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat[0][0] = eigenvalues[0]\n",
    "mat[1][1] = eigenvalues[1]\n",
    "mat[2][2] = eigenvalues[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.48756162, 0.        , 0.        ],\n",
       "       [0.        , 0.94435407, 0.        ],\n",
       "       [0.        , 0.        , 0.72597904]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-4) 자 이제 고유값 분해를 할 모든 준비가 되었어요 고유값 분해의 곱으로 원래 공분산 행렬을 구해보세요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html 를 참고해서 행렬 끼리 곱하시면 됩니다\n",
    "\n",
    "행렬 곱으로 eigenvector x mat x eigenvector.T 하면 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.05263158, -0.2037104 , -0.12079228],\n",
       "       [-0.2037104 ,  1.05263158,  0.3125801 ],\n",
       "       [-0.12079228,  0.3125801 ,  1.05263158]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(np.dot(eigenvectors,mat),eigenvectors.T) #행렬곱 dot을 이용, 고유값 분해 곱으로 공분산 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-5) 마지막으로 고유 벡터 축으로 값을 변환해 볼게요\n",
    "\n",
    "함수로 한번 정의해 보았어요\n",
    "\n",
    "https://docs.scipy.org/doc/numpy/reference/generated/numpy.concatenate.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_coordinates(X,eigenvectors):\n",
    "    for i in range(eigenvectors.shape[0]):\n",
    "        if i == 0:\n",
    "            new = [X.dot(eigenvectors.T[i])]\n",
    "        else:\n",
    "            new = np.concatenate((new,[X.dot(eigenvectors.T[i])]),axis=0)\n",
    "    return new.T\n",
    "#X, eigenvector 행렬곱을 통해 데이터를 projection\n",
    "\n",
    "# 모든 고유 벡터 축으로 데이터를 projection한 값입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_coordinates(X_std,eigenvectors)\n",
    "\n",
    "# 새로운 축으로 변환되어 나타난 데이터들입니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) PCA를 구현해 보세요\n",
    "\n",
    "위의 과정을 이해하셨다면 충분히 하실 수 있을거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def MYPCA(X,number):\n",
    "    scaler = StandardScaler()\n",
    "    x_std = scaler.fit_transform(X) #scaling\n",
    "    features = x_std.T\n",
    "    cov_matrix = np.cov(features) #공분산\n",
    "    \n",
    "    eigenvalues = lin.eig(cov_matrix)[0] #eigenvalue\n",
    "    eigenvectors = lin.eig(cov_matrix)[1] #eigenvector\n",
    "    \n",
    "    new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    new_coordinate = new_coordinates(x_std,eigenvectors)\n",
    "    \n",
    "    index = eigenvalues.argsort()\n",
    "    index = list(index)\n",
    "    \n",
    "    for i in range(number):\n",
    "        if i==0:\n",
    "            new = [new_coordinate[:,index.index(i)]]\n",
    "        else:\n",
    "            new = np.concatenate(([new_coordinate[:,index.index(i)]],new),axis=0)\n",
    "    return new.T #모든 고유벡터 축으로 projection하여 새로운 축에 나타난 데이터 return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3)\n",
    "\n",
    "# 새로운 축으로 잘 변환되어서 나타나나요? #넵!\n",
    "# 위에서 했던 PCA랑은 차이가 있을 수 있어요 왜냐하면 위에서는 고유값이 큰 축 순서로 정렬을 안했었거든요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) sklearn이랑 비교를 해볼까요?\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html 를 참고하시면 도움이 될거에요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3) #sklearn pca 사용 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.31019368 -1.08215716 -0.07983642]\n",
      " [-1.28092404 -0.43132556  0.13533091]\n",
      " [-1.38766381  0.78428014 -0.12911446]\n",
      " [-0.95087515 -1.15737142  1.6495519 ]\n",
      " [-1.84222365  0.88189889  0.11493111]\n",
      " [ 1.12563709 -0.52680338  0.06564012]\n",
      " [ 2.71174416  0.63290138  0.71195473]\n",
      " [ 0.03100441 -0.20059783 -0.50339479]\n",
      " [-2.29618509  0.07661447  0.01087174]\n",
      " [ 0.61585248 -0.205764    1.82651199]\n",
      " [ 1.73320252  1.29971699  0.09045178]\n",
      " [ 0.82366049 -0.57164535 -0.27123176]\n",
      " [-0.75619512  0.73995175 -0.76710616]\n",
      " [ 0.42344386  0.26555394 -1.41533681]\n",
      " [ 0.39581307 -1.64646874  0.24104031]\n",
      " [ 0.88581498  0.15195119 -0.82271209]\n",
      " [-0.24587691  0.39139878 -1.15801831]\n",
      " [-0.14741103 -1.22874561 -0.03110396]\n",
      " [ 0.7161265  -0.56781471 -0.86180345]\n",
      " [-0.24475107  2.39442622  1.19337361]]\n"
     ]
    }
   ],
   "source": [
    "print(pca.fit_transform(X_std)) #fir, transform x는 이미 스케일링한 x_std 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.31019368, -1.08215716, -0.07983642],\n",
       "       [ 1.28092404, -0.43132556,  0.13533091],\n",
       "       [ 1.38766381,  0.78428014, -0.12911446],\n",
       "       [ 0.95087515, -1.15737142,  1.6495519 ],\n",
       "       [ 1.84222365,  0.88189889,  0.11493111],\n",
       "       [-1.12563709, -0.52680338,  0.06564012],\n",
       "       [-2.71174416,  0.63290138,  0.71195473],\n",
       "       [-0.03100441, -0.20059783, -0.50339479],\n",
       "       [ 2.29618509,  0.07661447,  0.01087174],\n",
       "       [-0.61585248, -0.205764  ,  1.82651199],\n",
       "       [-1.73320252,  1.29971699,  0.09045178],\n",
       "       [-0.82366049, -0.57164535, -0.27123176],\n",
       "       [ 0.75619512,  0.73995175, -0.76710616],\n",
       "       [-0.42344386,  0.26555394, -1.41533681],\n",
       "       [-0.39581307, -1.64646874,  0.24104031],\n",
       "       [-0.88581498,  0.15195119, -0.82271209],\n",
       "       [ 0.24587691,  0.39139878, -1.15801831],\n",
       "       [ 0.14741103, -1.22874561, -0.03110396],\n",
       "       [-0.7161265 , -0.56781471, -0.86180345],\n",
       "       [ 0.24475107,  2.39442622,  1.19337361]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MYPCA(X,3) #앞서 구한 값과 비교!하면 첫번째 값들이 +-가 반대로 나왔네용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) MNIST data에 적용을 해볼게요!\n",
    "\n",
    "mnist data를 따로 내려받지 않게 압축파일에 같이 두었어요~!!!\n",
    "\n",
    "mnist-original.mat 파일과 같은 위치에서 주피터 노트북을 열어주세요~!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as lin\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "from scipy import io\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# mnist 손글씨 데이터를 불러옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = io.loadmat('mnist-original.mat') \n",
    "X = mnist['data'].T\n",
    "y = mnist['label'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data information\n",
    "\n",
    "# 7만개의 작은 숫자 이미지\n",
    "# 행 열이 반대로 되어있음 -> 전치\n",
    "# grayscale 28x28 pixel = 784 feature\n",
    "# 각 picel은 0~255의 값\n",
    "# label = 1~10 label이 총 10개인거에 주목하자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data를 각 픽셀에 이름붙여 표현\n",
    "feat_cols = [ 'pixel'+str(i) for i in range(X.shape[1]) ]\n",
    "df = pd.DataFrame(X,columns=feat_cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df에 라벨 y를 붙여서 데이터프레임 생성\n",
    "df['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0           0       0       0       0       0       0       0       0       0   \n",
       "1           0       0       0       0       0       0       0       0       0   \n",
       "2           0       0       0       0       0       0       0       0       0   \n",
       "3           0       0       0       0       0       0       0       0       0   \n",
       "4           0       0       0       0       0       0       0       0       0   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "69995       0       0       0       0       0       0       0       0       0   \n",
       "69996       0       0       0       0       0       0       0       0       0   \n",
       "69997       0       0       0       0       0       0       0       0       0   \n",
       "69998       0       0       0       0       0       0       0       0       0   \n",
       "69999       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "69995       0  ...         0         0         0         0         0   \n",
       "69996       0  ...         0         0         0         0         0   \n",
       "69997       0  ...         0         0         0         0         0   \n",
       "69998       0  ...         0         0         0         0         0   \n",
       "69999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783    y  \n",
       "0             0         0         0         0  0.0  \n",
       "1             0         0         0         0  0.0  \n",
       "2             0         0         0         0  0.0  \n",
       "3             0         0         0         0  0.0  \n",
       "4             0         0         0         0  0.0  \n",
       "...         ...       ...       ...       ...  ...  \n",
       "69995         0         0         0         0  9.0  \n",
       "69996         0         0         0         0  9.0  \n",
       "69997         0         0         0         0  9.0  \n",
       "69998         0         0         0         0  9.0  \n",
       "69999         0         0         0         0  9.0  \n",
       "\n",
       "[70000 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 지금까지 배운 여러 머신러닝 기법들이 있을거에요\n",
    "\n",
    "4-1) train_test_split을 통해 데이터를 0.8 0.2의 비율로 분할 해 주시고요\n",
    "\n",
    "4-2) PCA를 이용하여 mnist data를 축소해서 학습을 해주세요 / test error가 제일 작으신 분께 상품을 드리겠습니다 ^0^\n",
    "\n",
    "특정한 틀 없이 자유롭게 하시면 됩니다!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 trian, test data split 진행!\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pca를 사용하기 위해 미리 scaling진행\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_std = scaler.transform(X_train)    #train set은 fit, transform 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_std = scaler.transform(X_test)     #test set은 transform만 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 주성분 개수를 정하기 위해 \n",
    "1. Elbow point : 곡선의 기울기가 급격히 감소하는 지점\n",
    "2. Kaiser’s Rule : 고유값 1 이상의 주성분들\n",
    "3. 누적설명률이 70%~80% 이상인 지\n",
    "이 세가지 확인!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 784)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#먼저 2번 Kaiser's Rule을 확인!\n",
    "\n",
    "#먼저 trainset의 공분산을 구해주고\n",
    "cov_mat = np.cov(X_train.T)\n",
    "\n",
    "cov_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_values_raw, components_raw = lin.eig(cov_mat) #고유값eigenvalue를 구한다\n",
    "\n",
    "pca_1 = len(explain_values_raw[explain_values_raw > 1]) #고유값이 1이상의 주성분들로 차원축소하는 pca\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(pca_1).fit(X_train_std)\n",
    "\n",
    "pca_X_train = pca.transform(X_train_std)\n",
    "\n",
    "pca_X_test = pca.transform(X_test_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56000, 652)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_X_train.shape #확인 결과 2번으로는 주성분 개수를 655개로 줄여야 하지만 너무 많기 때문에\n",
    "#다른 조건들도 확인하기로 결정하였습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그 다음 1번 elbow point를 확인해보기로 결정하였습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 652)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sing_vals = range(pca.n_components_)\n",
    "sing_vals\n",
    "#앞서 줄인 651개 중에서 explained_variance_ratio를 통해\n",
    "#이 때 explained variance란!\n",
    "#각각의 주성분 벡터가 이루는 축에 projection한 결과의 분산의 비율, 즉 각 eigenvalue의 비율을 말함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals = pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x197dbf25608>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAWNklEQVR4nO3dfYxcV33G8e9jO4m9SciLsxQUv6yjuBSnLYFuDYgXlQZaJ2pxqwbhdFBcyZJ5iwSitHVkBUEkS6RCGCqSEJOkNcm2DpjSrmjagGJaqVXleNwEEjt12Rjb2ZrWmzi42MZxNvn1j3vHmZ2d2bm7Hu/MnHk+0tXOPffM7m+t8TNnz5x7ryICMzNL15x2F2BmZueWg97MLHEOejOzxDnozcwS56A3M0vcvHYXUOuKK66IgYGBdpdhZtZVdu/e/VxE9Nc71nFBPzAwQLlcbncZZmZdRdLBRsc8dWNmljgHvZlZ4hz0ZmaJc9CbmSXOQW9mlrh0gn5oCAYGYM6c7OvQULsrMjPrCB23vHJGhoZg/Xo4eTLbP3gw2wcoldpXl5lZB0hjRL9x46shX3HyZNZuZtbj0gj6Q4em125m1kPSCPolS6bXbmbWQ9II+k2boK9vYltfX9ZuZtbj0gj6Ugm2bAEp25Yuzfb9QayZWSJBD1moX345HDkCBw445M3McukEPWRr6F95pd1VmJl1FAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVni0gv6l19udxVmZh0lraCfO9cjejOzGmkFvaduzMwmcdCbmSXOQW9mljgHvZlZ4hz0ZmaJc9CbmSUuvaD3OnozswkKBb2kVZL2SRqRtKHO8QskPZQf3ylpIG8fkPRzSU/k21dbW34Nr6M3M5tkXrMOkuYCdwLvA0aBXZKGI2JvVbd1wAsRcbWkNcAdwAfzY89ExLUtrrs+T92YmU1SZES/EhiJiP0RcRrYBqyu6bMa2Jo/3g5cJ0mtK7MgB72Z2SRFgv5K4Nmq/dG8rW6fiBgHjgEL82PLJD0u6V8kvaveD5C0XlJZUnlsbGxav8AEDnozs0mKBH29kXkU7PMTYElEvBn4FPDXkl4zqWPElogYjIjB/v7+AiU14KA3M5ukSNCPAour9hcBhxv1kTQPuAQ4GhEvRsTzABGxG3gG+MWzLbohB72Z2SRFgn4XsFzSMknnA2uA4Zo+w8Da/PGNwI6ICEn9+Ye5SLoKWA7sb03pdTjozcwmabrqJiLGJd0CPALMBe6PiD2SbgfKETEM3Ac8IGkEOEr2ZgDwbuB2SePAy8BHIuLoufhFAK+jNzOro2nQA0TEw8DDNW2fqXp8CvhAned9C/jWWdZYnEf0ZmaTpHVmrE+YMjObJK2g94jezGwSB72ZWeIc9GZmiXPQm5klzkFvZpa49ILe6+jNzCZIL+g9ojczmyCtoPc6ejOzSdIKeo/ozcwmcdCbmSXOQW9mljgHvZlZ4hz0ZmaJSy/ovY7ezGyC9ILeI3ozswnSCnqvozczmyStoPeI3sxsEge9mVniHPRmZolz0JuZJc5Bb2aWuPSC3uvozcwmSC/oPaI3M5sgraD3Onozs0nSCfqhIfjKV+C222BgINs3M7NiQS9plaR9kkYkbahz/AJJD+XHd0oaqDm+RNJxSZ9uTdk1hoZg/Xo4dizbP3gw23fYm5k1D3pJc4E7geuBFcBNklbUdFsHvBARVwObgTtqjm8G/vHsy21g40Y4eXJi28mTWbuZWY8rMqJfCYxExP6IOA1sA1bX9FkNbM0fbweukyQASb8H7Af2tKbkOg4dml67mVkPKRL0VwLPVu2P5m11+0TEOHAMWCjpQuDPgM9N9QMkrZdUllQeGxsrWvurliyZXruZWQ8pEvSq0xYF+3wO2BwRx6f6ARGxJSIGI2Kwv7+/QEk1Nm2Cvr6JbX19WbuZWY+bV6DPKLC4an8RcLhBn1FJ84BLgKPAW4EbJf05cCnwiqRTEfGVs668WqmUff3kJ+G552Dp0izkK+1mZj2sSNDvApZLWgb8N7AG+MOaPsPAWuDfgRuBHRERwLsqHSR9Fjje8pCvKJWgvx++8AX47nfPyY8wM+tGTYM+IsYl3QI8AswF7o+IPZJuB8oRMQzcBzwgaYRsJL/mXBbd0IUXwvEpZ4nMzHpOkRE9EfEw8HBN22eqHp8CPtDke3x2BvVNz0UXOejNzGqkdWbsDTfAk0/6zFgzsyqFRvQdr3JmbOWkqcqZseAPZM2s56UxoveZsWZmDaUR9D4z1sysoTSC3mfGmpk1lEbQ+8xYM7OG0gj6Ugm2bMnOiAVYvDjb9wexZmaJrLqBLNRLpWwt/d692VczM0tkRF9t3jwYH293FWZmHcNBb2aWOAe9mVni0gz6l15qdxVmZh0jzaD3iN7M7Iz0gv688xz0ZmZV0gt6j+jNzCZw0JuZJc5Bb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVni0gx6XwLBzOyMNIPeI3ozszPSC3pfAsHMbIL0gt4jejOzCQoFvaRVkvZJGpG0oc7xCyQ9lB/fKWkgb18p6Yl8+4Gk329t+XU46M3MJmga9JLmAncC1wMrgJskrajptg54ISKuBjYDd+TtTwGDEXEtsAq4R9K5vU+tg97MbIIiI/qVwEhE7I+I08A2YHVNn9XA1vzxduA6SYqIkxFRSd35QLSi6Ck56M3MJigS9FcCz1btj+ZtdfvkwX4MWAgg6a2S9gBPAh+pCv4zJK2XVJZUHhsbm/5vUTE0BN/8JqxbBwMD2b6ZWY8rEvSq01Y7Mm/YJyJ2RsQ1wK8Dt0qaP6ljxJaIGIyIwf7+/gIl1TE0BOvXw/Hj2f7Bg9m+w97MelyRoB8FFlftLwION+qTz8FfAhyt7hARTwMngF+eabFT2rgRTp6c2HbyZNZuZtbDigT9LmC5pGWSzgfWAMM1fYaBtfnjG4EdERH5c+YBSFoKvAE40JLKax06NL12M7Me0XQFTESMS7oFeASYC9wfEXsk3Q6UI2IYuA94QNII2Uh+Tf70dwIbJL0EvAJ8LCKeOxe/CEuWZNM19drNzHqYIs79QpjpGBwcjHK5PP0nVuboq6dv+vpgyxYolVpXoJlZB5K0OyIG6x1L58zYUikL9csuy/aXLnXIm5lRYOqmq5RKcOIE7NoFX/tau6sxM+sI6YzoK/r64Oc/b3cVZmYdI82gr11maWbWw9IL+gULHPRmZlXSC3pP3ZiZTZBm0HtEb2Z2RlpBPzQEq1dDueyLmpmZ5dJZXll7wlTlombgtfRm1tPSGdH7omZmZnWlE/S+qJmZWV3pBH2ji5f5omZm1uPSCfpNm7IVN9X6+rJ2M7Melk7QVy5qtnRptr94sS9qZmZGSqtuIAv1Ugle9zp47LHsq5lZj0tnRF/NJ02ZmZ3hoDczS1yaQb9gga93Y2aWSzPoPaI3MzsjvaAfGso+iH3Pe3y9GzMzUlt1U7nezalT2b6vd2NmltiI3te7MTObJK2g9/VuzMwmSSvofb0bM7NJ0gp6X+/GzGyStIK+cr2bSy/N9pcu9fVuzKznFVp1I2kV8GVgLnBvRHy+5vgFwNeBXwOeBz4YEQckvQ/4PHA+cBr4k4jY0cL6JyuV4Gc/g8cfh3vuOac/ysysGzQd0UuaC9wJXA+sAG6StKKm2zrghYi4GtgM3JG3Pwf8bkT8CrAWeKBVhU/poovg+PFZ+VFmZp2uyNTNSmAkIvZHxGlgG7C6ps9qYGv+eDtwnSRFxOMRcThv3wPMz0f/59bFFzvozcxyRYL+SuDZqv3RvK1un4gYB44BC2v6/AHweES8WPsDJK2XVJZUHhsbK1p7fZWTpoaHfWasmRnFgl512mI6fSRdQzad8+F6PyAitkTEYEQM9vf3FyipgUrIHzmS7VfOjHXYm1kPKxL0o8Diqv1FwOFGfSTNAy4Bjub7i4BvAzdHxDNnW/CUfGasmdkkRYJ+F7Bc0jJJ5wNrgOGaPsNkH7YC3AjsiIiQdCnwD8CtEfFvrSq6IZ8Za2Y2SdOgz+fcbwEeAZ4GvhEReyTdLun9ebf7gIWSRoBPARvy9luAq4HbJD2Rb69t+W9R4TNjzcwmUUTtdHt7DQ4ORrlcntmTK3P01dM3fX0+acrMkidpd0QM1juW5pmxC6sW/CxY0L56zMw6QFpBX1F9G8Hnn/fKGzPraekFvVfemJlNkF7Qe+WNmdkE6QW9V96YmU2QXtD7mvRmZhOkF/SVlTeXX57t+5r0Ztbj0gv6ijnp/mpmZtNR6MYjXaX2pKnKhc3Ao3oz60npDXu9vNLMbIL0gt7LK83MJkgv6L280sxsgvSCvt7ySgluuKE99ZiZtVl6QV8qwdq1WbhXRMDWrb7ejZn1pPSCHuDhh7Nwr+YPZM2sR6UZ9AcPTq/dzCxhaQb93LnTazczS1iaQf/yy9NrNzNLWJpBv3Tp9NrNzBKWZtB7iaWZ2RlpBr2XWJqZnZFm0IOXWJqZ5dINel/zxswMSDnoKzceqVU7d29mlrh0g76REyc8T29mPSXdoD96tPExz9ObWQ8pFPSSVknaJ2lE0oY6xy+Q9FB+fKekgbx9oaTvSzou6SutLb2JqS5L7EshmFkPaRr0kuYCdwLXAyuAmyStqOm2DnghIq4GNgN35O2ngNuAT7es4qI2bZr6uKdvzKxHFBnRrwRGImJ/RJwGtgGra/qsBrbmj7cD10lSRJyIiH8lC/zZ1ez+sJ6+MbMeUSTorwSerdofzdvq9omIceAYsLBoEZLWSypLKo+NjRV9WnNTXfLAyyzNrEcUCXrVaYsZ9GkoIrZExGBEDPb39xd9WnNTTd+cd17rfo6ZWQcrEvSjwOKq/UXA4UZ9JM0DLgGmWPYyS0qliZdBqHb6tOfpzawnFAn6XcByScsknQ+sAYZr+gwDa/PHNwI7ImqvP9AmU5Xx4Q/PXh1mZm3SNOjzOfdbgEeAp4FvRMQeSbdLen/e7T5goaQR4FPAmSWYkg4AXwT+SNJonRU759ZUNxvxyVNm1gPUKQPvisHBwSiXy637hh/7GNx9d+PjF14Ix4+37ueZmbWBpN0RMVjvWLpnxlbcdRfMn9/4uEf1Zpa49IMe4N57pz7uuXozS1hvBH2pBBdd1Pj4iRPZFI+ZWYJ6I+gBvvrVqY/ffbencMwsSb0T9M1G9eApHDNLUu8EPTQf1Z84Ae997+zUYmY2S3or6IuM6h99FK65ZnbqMTObBb0V9NB8VA+wd6/D3syS0XtBXyrBRz/avJ/D3swS0XtBD9lJVM2mcMBhb2ZJ6M2gh2wKp9GVLavt3Zv18zp7M+tSvRv0pRI88EDx/nffnQW+V+WYWZfp3aCHLOwffHB6z3n0UY/wzayr9HbQw6thP9XljOupjPAvvthn1JpZR3PQQxb24+OwYgaXyj9+HD70oSz0Fyxw6JtZx3HQV9uzZ2ZhX3Hq1Kuh79G+mXUIB32tPXuKrbMvonq0X73NmeM5fjObNQ76eu66K7vXbKsCv1bEq3P81Zv/AjCzc8BBP5VzHfi1Gv0F4CWdZnYWHPRFzHbg16os6ay3+U3AzJpw0E9HJfAffDC7qXgnmOpNwJ8HmBkO+pkplbJplk4L/XoafR7QbPPnBWbJcNCfrerQ74bgL6rR5wV+czDrOg76VqsN/uqtXXP8s2Umbw6eZjI75xz0s6kyx1+9pfIXQCvMdJppppvPZLYe4aBvt0Z/AaQ++u8EtWcy9+rmv6KSVyjoJa2StE/SiKQNdY5fIOmh/PhOSQNVx27N2/dJ+u3WlZ64eqN/vwnYuTCbf0V5a76dg780mwa9pLnAncD1wArgJkm1F4RZB7wQEVcDm4E78ueuANYA1wCrgLvy72dnY6o3Ab8ZmHW3U6fg5ptbGvZFRvQrgZGI2B8Rp4FtwOqaPquBrfnj7cB1kpS3b4uIFyPix8BI/v3sXCvyZuDPC8w60yuvwMaNLft2RYL+SuDZqv3RvK1un4gYB44BCws+F0nrJZUllcfGxopXb6011Yoh/+VgNrsOHWrZtyoS9KrTFgX7FHkuEbElIgYjYrC/v79ASdYxZvKXg98szJpbsqRl36pI0I8Ci6v2FwGHG/WRNA+4BDha8LnW61rxZuHpKUvJnDmwaVPrvl2BPruA5ZKWSTqf7MPV4Zo+w8Da/PGNwI6IiLx9Tb4qZxmwHHisNaWbzcBMpqdS3PxXVOeaPx++/vXstdoi85p1iIhxSbcAjwBzgfsjYo+k24FyRAwD9wEPSBohG8mvyZ+7R9I3gL3AOPDxiHi5ZdWb2czcdVe2WU9QNvDuHIODg1Eul9tdhplZV5G0OyIG6x3zmbFmZolz0JuZJc5Bb2aWOAe9mVniOu7DWEljwMGz+BZXAM+1qJzZ1K11g2tvl26tvVvrhs6ufWlE1D3jtOOC/mxJKjf65LmTdWvd4NrbpVtr79a6oXtr99SNmVniHPRmZolLMei3tLuAGerWusG1t0u31t6tdUOX1p7cHL2ZmU2U4ojezMyqOOjNzBKXTNA3u4F5u0m6X9IRSU9VtV0u6XuSfpR/vSxvl6S/yH+XH0p6SxvrXizp+5KelrRH0ie6qPb5kh6T9IO89s/l7cvym9j/KL+p/fl5e8Ob3LeLpLmSHpf0nXy/K2qXdEDSk5KekFTO27rhNXOppO2S/jN/zb+9G+puJomgV7EbmLfbX5HdIL3aBuDRiFgOPJrvQ/Z7LM+39cDds1RjPePAH0fEG4G3AR/P/227ofYXgd+MiDcB1wKrJL2N7Ob1m/PaXyC7uT00uMl9m30CeLpqv5tqf09EXFu17rwbXjNfBv4pIn4JeBPZv3031D21iOj6DXg78EjV/q3Are2uq06dA8BTVfv7gNfnj18P7Msf3wPcVK9fuzfg74H3dVvtQB/wH8Bbyc5snFf72iG758Lb88fz8n5qY82LyILlN4HvkN2as1tqPwBcUdPW0a8Z4DXAj2v/3Tq97iJbEiN6Ct6EvAP9QkT8BCD/+tq8vSN/n3w64M3ATrqk9nzq4wngCPA94Bngp5HdxL62vkY3uW+XLwF/CryS7y+ke2oP4LuSdktan7d1+mvmKmAM+Mt8uuxeSRfS+XU3lUrQF7oJeRfpuN9H0kXAt4BPRsT/TdW1Tlvbao+IlyPiWrLR8UrgjfW65V87pnZJvwMciYjd1c11unZc7bl3RMRbyKY3Pi7p3VP07ZTa5wFvAe6OiDcDJ3h1mqaeTqm7qVSCvltvQv6/kl4PkH89krd31O8j6TyykB+KiL/Nm7ui9oqI+Cnwz2SfM1yq7Cb2MLG+Rje5b4d3AO+XdADYRjZ98yW6o3Yi4nD+9QjwbbI32U5/zYwCoxGxM9/fThb8nV53U6kEfZEbmHei6puqryWb/66035x/qv824FjlT8fZJklk9wR+OiK+WHWoG2rvl3Rp/ngB8F6yD9e+T3YTe5hce72b3M+6iLg1IhZFxADZ63lHRJTogtolXSjp4spj4LeAp+jw10xE/A/wrKQ35E3Xkd3vuqPrLqTdHxK0agNuAP6LbA52Y7vrqVPf3wA/AV4iGwmsI5tDfRT4Uf718ryvyFYRPQM8CQy2se53kv05+kPgiXy7oUtq/1Xg8bz2p4DP5O1XAY8BI8A3gQvy9vn5/kh+/Kp2v27yun4D+E631J7X+IN821P5/9glr5lrgXL+mvk74LJuqLvZ5ksgmJklLpWpGzMza8BBb2aWOAe9mVniHPRmZolz0JuZJc5Bb2aWOAe9mVni/h+g8cayrmXDWQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sing_vals, eigvals, 'ro-', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 40)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(sing_vals, eigvals, 'ro-', linewidth=1)\n",
    "plt.xlim(0,40)\n",
    "#줄이고 줄인 결과적으로  30-40 정도가 적당하다고 판단했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#마지막으로 누적설명률을 판단했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.8)\n",
    "\n",
    "\n",
    "pca.fit(X_train_std)\n",
    "\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.75)\n",
    "\n",
    "\n",
    "pca.fit(X_train_std)\n",
    "\n",
    "pca.n_components_\n",
    "\n",
    "#scaling한 데이터는 120개 정도가 적당하다 판단했고"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#그래서 스케일링하지 않은 데이터도 확인해보고싶어서\n",
    "#스케일링하지 않은 데이터는 주성분개수 43 또는 33이 적당하다 판단했습니다\n",
    "\n",
    "pca = PCA(n_components=0.8)\n",
    "\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.75)\n",
    "\n",
    "pca.fit(X_train)\n",
    "\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "먼저 randomforest 모델을 사용했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=120, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train_std)\n",
    "new_X_test = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451428571428572"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(new_X_test,y_test)\n",
    "\n",
    "#scaling 한 데이터 주성분 개수 120으로 했을 때 0.945"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일링을 안했을 때/ 주성분개수 43으로 해봤습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=43, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=43)\n",
    "\n",
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train)\n",
    "new_X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.955"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(new_X_test,y_test)  \n",
    "#스케일링하지 않은 데이터/randomforest 사용/주성분개수 43\n",
    "#accuracy: 0.955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=33, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train)\n",
    "new_X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "clf.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9532857142857143"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(new_X_test,y_test)\n",
    "#스케일링하지 않은 데이터/randomforest 사용/주성분개수 33\n",
    "#accuracy: 0.953"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#두번째로 SVM모델 사용했습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#먼저 scaling한 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=120, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train_std)\n",
    "new_X_test = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel = 'rbf') #rbf kernel만 파라미터 설정하고 돌려보았습니다\n",
    "\n",
    "svc.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9690714285714286"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(new_X_test,y_test)\n",
    "#스케일링한 데이터, 주성분 개수 120\n",
    "#0.969"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일링하지 않은 데이터 주성분개수 43/33개로 해보았습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=43, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train)\n",
    "new_X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel = 'rbf') #rbf kernel만 파라미터 설정하고 돌려보았습니다\n",
    "\n",
    "svc.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9822142857142857"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(new_X_test,y_test)\n",
    "\n",
    "#스케일링하지 않은 데이터/svm 사용/주성분개수 43\n",
    "#accuracy: 0.9822!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=33, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X_train = pca.transform(X_train)\n",
    "new_X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(kernel = 'rbf')\n",
    "\n",
    "svc.fit(new_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9800714285714286"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.score(new_X_test,y_test)\n",
    "\n",
    "#스케일링 안한 데이터/ SVM / 주성분개수 33\n",
    "#accuracy 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#스케일링하지 않은 데이터에, 주성분 개수가 43이 제일 적당한 것 같고 svm이 좋은 모델임을 확인하였습니다!\n",
    "\n",
    "#가장 좋았던 accuracy는 0.9822!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
