{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 인공신경망 기초 (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 과제 내용 설명\n",
    "1. 인공신경망의 오차 역전파 과정을 직접 필기하여 계산해주세요\n",
    "2. 인공 신경망을 구현하는 실습파일을 완성해주세요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 우수과제 선정 이유\n",
    "개념을 하나 하나 정리하신 점이 인상 깊었습니다. 또한, 코드에 대한 해설과 함께 결과 해석까지 모두 해주셨습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 1) 오차 역전파 계산\n",
    "![img1](https://imgur.com/1cgzZEa.jpg)\n",
    "\n",
    "![img2](https://imgur.com/aAoAcit.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2) 인공 신경망 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614]}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095]}, {'weights': [0.4494910647887381, 0.651592972722763]}]\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    " \n",
    "# 네트워크 초기 설정\n",
    "def initialize_network(n_inputs, n_hidden, n_outputs):\n",
    "    network = list()\n",
    "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(n_hidden)] \n",
    "    #hidden layer*(1(bias term)+input수)->weight수 결정! 히든레이어로 갈때 가중치는 총 3개 발생\n",
    "    network.append(hidden_layer)\n",
    "    output_layer = [{'weights':[random() for i in range(n_hidden + 1)]} for i in range(n_outputs)]\n",
    "    #히든레이어에서 output레이어로 넘어갈때 output수 2이므로 각각 2(히든레이어수+1)개씩 총 4개의 weight가 발생\n",
    "    network.append(output_layer)\n",
    "    return network\n",
    " \n",
    "seed(1)\n",
    "network = initialize_network(2, 1, 2)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activate(weights, inputs):\n",
    "    activation = weights[-1]\n",
    "    for i in range(len(weights)-1):\n",
    "        activation += weights[i] * inputs[i] # 순전파 진행 \n",
    "        #weight * inputs 곱한거를 return 값으로 받은 후\n",
    "    return activation\n",
    "\n",
    "def sigmoid(activation): #activation function으로 sigmoid 선택(영역을 영역으로 변환)\n",
    "    return 1.0 / (1.0 + np.exp(-activation)) # 시그모이드 구현\n",
    "\n",
    "#활성화 함수의 역할은! nn에서 입력받은 데이터를 다음층으로 출력할지를 결정\n",
    "\n",
    "#하나의 노드가 1개이상의 노드와 연결되어있고\n",
    "#데이터 입력을 받게 되는데 연결강도의 가중치의 합을 구하게 되고\n",
    "#활성화 함수를 통해 weights 값의 크기에 따라 출력하게 되는 것!\n",
    "\n",
    "#먼저 순전파 propagation을 진행한다\n",
    "def forward_propagate(network, row):\n",
    "    inputs = row\n",
    "    for layer in network:\n",
    "        new_inputs = []\n",
    "        for neuron in layer:\n",
    "            activation = activate(neuron['weights'], inputs)  #weight와 input값을 곱한 계산값을\n",
    "            neuron['output'] = sigmoid(activation) # 나온 계산 값을 그대로 쓰나요? #아니요! 시그모이드 함수에 넣어줍니다\n",
    "            new_inputs.append(neuron['output']) # new_input은 다음 히든층에 들어갈 값이죠? #넵\n",
    "        inputs = new_inputs\n",
    "    return inputs #한번의 순전파를 거친 output이 다음 hiddenlayer의 input값이 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**여기까지는 순전파 학습과정이었습니다. 이 과정이 끝나면 가중치가 바뀌나요?  \n",
    "답변을 답변의 근거 코딩 결과와 함께 보여주세요.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095], 'output': 0.6629970129852887}, {'weights': [0.4494910647887381, 0.651592972722763], 'output': 0.7253160725279748}]\n"
     ]
    }
   ],
   "source": [
    "row = [1, 0, None]\n",
    "forward_propagate(network,row)\n",
    "for layer in network:\n",
    "    print(layer)\n",
    "    \n",
    "#순전파 학습과정을 거친 후 weight는 바뀌지 않는다!\n",
    "#가중치가 바뀌는 과정은 오류역전파 과정에서 일어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6629970129852887, 0.7253160725279748]\n"
     ]
    }
   ],
   "source": [
    "row = [1, 0, None]\n",
    "output = forward_propagate(network, row)\n",
    "print(output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in reversed(range(len(network))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(output):\n",
    "    return output * (1.0 - output) # 시그모이드 미분\n",
    "\n",
    "#오류역전파 진행합니다\n",
    "def backward_propagate_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = []\n",
    "        #i = 0 일때 2번째로\n",
    "        if i != len(network)-1:\n",
    "            for j in range(len(layer)):\n",
    "                error = 0.0\n",
    "                for neuron in network[i + 1]: \n",
    "                    error += (neuron['weights'][j] * neuron['delta']) #앞에서 구한 delta값을 기반으로 error 구한다\n",
    "                errors.append(error) \n",
    "        # i =1 일때 1번으로!\n",
    "        else:\n",
    "            for j in range(len(layer)): \n",
    "                neuron = layer[j]\n",
    "                errors.append(expected[j] - neuron['output']) \n",
    "                # 역전파시 오차는 어떻게 설정했나요?\n",
    "                #함수인자로 받은 예상값 expected와 앞서 순전파로 구한 output값의 차\n",
    "        for j in range(len(layer)):\n",
    "            neuron = layer[j] \n",
    "            neuron['delta'] =  errors[j] * sigmoid_derivative(neuron['output'])\n",
    "            #델타값은 앞서 구한 오류 값 * 순전파 과정으로 구한 output을 시그모이드 미분한 함수에 넣은 값 으로 구한다\n",
    "            # 시그모이드 함수를 사용한 역전파 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.13436424411240122, 0.8474337369372327, 0.763774618976614], 'output': 0.7105668883115941, 'delta': -0.002711797799238243}]\n",
      "[{'weights': [0.2550690257394217, 0.49543508709194095], 'output': 0.6629970129852887, 'delta': -0.14813473120687762}, {'weights': [0.4494910647887381, 0.651592972722763], 'output': 0.7253160725279748, 'delta': 0.05472601157879688}]\n"
     ]
    }
   ],
   "source": [
    "expected = [0, 1]\n",
    "\n",
    "backward_propagate_error(network, expected)\n",
    "for layer in network:\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#역전파 과정을 토대로 가중치를 업데이트 시킨다\n",
    "def weights_update(network, row, l_rate): \n",
    "    for i in range(len(network)):\n",
    "        inputs = row[:-1]\n",
    "        if i != 0:\n",
    "            inputs = [neuron['output'] for neuron in network[i - 1]] #앞서 구한 output을 input으로 \n",
    "        for neuron in network[i]:\n",
    "            for j in range(len(inputs)):\n",
    "                neuron['weights'][j] += l_rate * neuron['delta'] * inputs[j] #앞서 구한 델타값과 learning rate를 곱해서 가중치에 더하는 방식으로 업데이트시킨다\n",
    "            neuron['weights'][-1] +=  l_rate * neuron['delta']  # 퍼셉트론 학습 규칙\n",
    "            \n",
    "#앞서 진행한 과정을 반복해서 error을 줄여나간다\n",
    "def train_network(network, train, l_rate, n_epoch, n_outputs):\n",
    "    for epoch in range(n_epoch):\n",
    "        sum_error = 0\n",
    "        for row in train:\n",
    "            outputs = forward_propagate(network,row) # 먼저 순전파진행 \n",
    "            expected = [0 for i in range(n_outputs)]\n",
    "            expected[row[-1]] = 1\n",
    "            sum_error += sum([(expected[i]- outputs[i])**2 for i in range(len(expected))])\n",
    "            # 예측값의 오차 합\n",
    "            #sum error확인-> 학습을 진행하면서 error가 줄어드는지 확인해야하니까\n",
    "            backward_propagate_error(network, expected) #그다음 역전파 진행\n",
    "            weights_update(network, row, l_rate) #역전파 기반 가중치를 업데이트 시킨다\n",
    "        #이과정을 지정한 epoch수만큼 반복\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "    [1.465489372,2.362125076,0],\n",
    "    [3.396561688,4.400293529,0],\n",
    "    [1.38807019,1.850220317,0],\n",
    "    [3.06407232,3.005305973,0],\n",
    "    [7.627531214,2.759262235,1],\n",
    "    [5.332441248,2.088626775,1],\n",
    "    [6.922596716,1.77106367,1],\n",
    "    [8.675418651,-0.242068655,1],\n",
    "    [7.673756466,3.508563011,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'weights': [0.762280082457942, 0.0021060533511106927, 0.4453871940548014]}, {'weights': [0.7215400323407826, 0.22876222127045265, 0.9452706955539223]}]\n",
      "[{'weights': [0.9014274576114836, 0.030589983033553536, 0.0254458609934608]}, {'weights': [0.5414124727934966, 0.9391491627785106, 0.38120423768821243]}]\n",
      ">epoch=0, lrate=1.000, error=6.153\n",
      ">epoch=1, lrate=1.000, error=5.621\n",
      ">epoch=2, lrate=1.000, error=5.606\n",
      ">epoch=3, lrate=1.000, error=5.569\n",
      ">epoch=4, lrate=1.000, error=5.467\n",
      ">epoch=5, lrate=1.000, error=5.215\n",
      ">epoch=6, lrate=1.000, error=4.842\n",
      ">epoch=7, lrate=1.000, error=4.397\n",
      ">epoch=8, lrate=1.000, error=3.908\n",
      ">epoch=9, lrate=1.000, error=3.415\n",
      ">epoch=10, lrate=1.000, error=2.937\n",
      ">epoch=11, lrate=1.000, error=2.438\n",
      ">epoch=12, lrate=1.000, error=2.051\n",
      ">epoch=13, lrate=1.000, error=1.670\n",
      ">epoch=14, lrate=1.000, error=1.401\n",
      ">epoch=15, lrate=1.000, error=1.204\n",
      ">epoch=16, lrate=1.000, error=1.046\n",
      ">epoch=17, lrate=1.000, error=0.919\n",
      ">epoch=18, lrate=1.000, error=0.815\n",
      ">epoch=19, lrate=1.000, error=0.730\n",
      ">epoch=20, lrate=1.000, error=0.659\n",
      ">epoch=21, lrate=1.000, error=0.599\n",
      ">epoch=22, lrate=1.000, error=0.549\n",
      ">epoch=23, lrate=1.000, error=0.505\n",
      ">epoch=24, lrate=1.000, error=0.468\n",
      ">epoch=25, lrate=1.000, error=0.435\n",
      ">epoch=26, lrate=1.000, error=0.406\n",
      ">epoch=27, lrate=1.000, error=0.381\n",
      ">epoch=28, lrate=1.000, error=0.358\n",
      ">epoch=29, lrate=1.000, error=0.338\n",
      ">epoch=30, lrate=1.000, error=0.319\n",
      ">epoch=31, lrate=1.000, error=0.303\n",
      ">epoch=32, lrate=1.000, error=0.288\n",
      ">epoch=33, lrate=1.000, error=0.274\n",
      ">epoch=34, lrate=1.000, error=0.262\n",
      ">epoch=35, lrate=1.000, error=0.250\n",
      ">epoch=36, lrate=1.000, error=0.240\n",
      ">epoch=37, lrate=1.000, error=0.230\n",
      ">epoch=38, lrate=1.000, error=0.221\n",
      ">epoch=39, lrate=1.000, error=0.212\n",
      ">epoch=40, lrate=1.000, error=0.205\n",
      ">epoch=41, lrate=1.000, error=0.197\n",
      ">epoch=42, lrate=1.000, error=0.191\n",
      ">epoch=43, lrate=1.000, error=0.184\n",
      ">epoch=44, lrate=1.000, error=0.178\n",
      ">epoch=45, lrate=1.000, error=0.173\n",
      ">epoch=46, lrate=1.000, error=0.167\n",
      ">epoch=47, lrate=1.000, error=0.162\n",
      ">epoch=48, lrate=1.000, error=0.158\n",
      ">epoch=49, lrate=1.000, error=0.153\n",
      ">epoch=50, lrate=1.000, error=0.149\n",
      ">epoch=51, lrate=1.000, error=0.145\n",
      ">epoch=52, lrate=1.000, error=0.141\n",
      ">epoch=53, lrate=1.000, error=0.138\n",
      ">epoch=54, lrate=1.000, error=0.134\n",
      ">epoch=55, lrate=1.000, error=0.131\n",
      ">epoch=56, lrate=1.000, error=0.128\n",
      ">epoch=57, lrate=1.000, error=0.125\n",
      ">epoch=58, lrate=1.000, error=0.122\n",
      ">epoch=59, lrate=1.000, error=0.119\n",
      ">epoch=60, lrate=1.000, error=0.116\n",
      ">epoch=61, lrate=1.000, error=0.114\n",
      ">epoch=62, lrate=1.000, error=0.112\n",
      ">epoch=63, lrate=1.000, error=0.109\n",
      ">epoch=64, lrate=1.000, error=0.107\n",
      ">epoch=65, lrate=1.000, error=0.105\n",
      ">epoch=66, lrate=1.000, error=0.103\n",
      ">epoch=67, lrate=1.000, error=0.101\n",
      ">epoch=68, lrate=1.000, error=0.099\n",
      ">epoch=69, lrate=1.000, error=0.097\n",
      ">epoch=70, lrate=1.000, error=0.095\n",
      ">epoch=71, lrate=1.000, error=0.094\n",
      ">epoch=72, lrate=1.000, error=0.092\n",
      ">epoch=73, lrate=1.000, error=0.090\n",
      ">epoch=74, lrate=1.000, error=0.089\n",
      ">epoch=75, lrate=1.000, error=0.087\n",
      ">epoch=76, lrate=1.000, error=0.086\n",
      ">epoch=77, lrate=1.000, error=0.084\n",
      ">epoch=78, lrate=1.000, error=0.083\n",
      ">epoch=79, lrate=1.000, error=0.082\n",
      ">epoch=80, lrate=1.000, error=0.080\n",
      ">epoch=81, lrate=1.000, error=0.079\n",
      ">epoch=82, lrate=1.000, error=0.078\n",
      ">epoch=83, lrate=1.000, error=0.077\n",
      ">epoch=84, lrate=1.000, error=0.076\n",
      ">epoch=85, lrate=1.000, error=0.075\n",
      ">epoch=86, lrate=1.000, error=0.074\n",
      ">epoch=87, lrate=1.000, error=0.073\n",
      ">epoch=88, lrate=1.000, error=0.071\n",
      ">epoch=89, lrate=1.000, error=0.071\n",
      ">epoch=90, lrate=1.000, error=0.070\n",
      ">epoch=91, lrate=1.000, error=0.069\n",
      ">epoch=92, lrate=1.000, error=0.068\n",
      ">epoch=93, lrate=1.000, error=0.067\n",
      ">epoch=94, lrate=1.000, error=0.066\n",
      ">epoch=95, lrate=1.000, error=0.065\n",
      ">epoch=96, lrate=1.000, error=0.064\n",
      ">epoch=97, lrate=1.000, error=0.063\n",
      ">epoch=98, lrate=1.000, error=0.063\n",
      ">epoch=99, lrate=1.000, error=0.062\n",
      ">epoch=100, lrate=1.000, error=0.061\n",
      ">epoch=101, lrate=1.000, error=0.060\n",
      ">epoch=102, lrate=1.000, error=0.060\n",
      ">epoch=103, lrate=1.000, error=0.059\n",
      ">epoch=104, lrate=1.000, error=0.058\n",
      ">epoch=105, lrate=1.000, error=0.058\n",
      ">epoch=106, lrate=1.000, error=0.057\n",
      ">epoch=107, lrate=1.000, error=0.056\n",
      ">epoch=108, lrate=1.000, error=0.056\n",
      ">epoch=109, lrate=1.000, error=0.055\n",
      ">epoch=110, lrate=1.000, error=0.055\n",
      ">epoch=111, lrate=1.000, error=0.054\n",
      ">epoch=112, lrate=1.000, error=0.053\n",
      ">epoch=113, lrate=1.000, error=0.053\n",
      ">epoch=114, lrate=1.000, error=0.052\n",
      ">epoch=115, lrate=1.000, error=0.052\n",
      ">epoch=116, lrate=1.000, error=0.051\n",
      ">epoch=117, lrate=1.000, error=0.051\n",
      ">epoch=118, lrate=1.000, error=0.050\n",
      ">epoch=119, lrate=1.000, error=0.050\n",
      ">epoch=120, lrate=1.000, error=0.049\n",
      ">epoch=121, lrate=1.000, error=0.049\n",
      ">epoch=122, lrate=1.000, error=0.048\n",
      ">epoch=123, lrate=1.000, error=0.048\n",
      ">epoch=124, lrate=1.000, error=0.047\n",
      ">epoch=125, lrate=1.000, error=0.047\n",
      ">epoch=126, lrate=1.000, error=0.046\n",
      ">epoch=127, lrate=1.000, error=0.046\n",
      ">epoch=128, lrate=1.000, error=0.046\n",
      ">epoch=129, lrate=1.000, error=0.045\n",
      ">epoch=130, lrate=1.000, error=0.045\n",
      ">epoch=131, lrate=1.000, error=0.044\n",
      ">epoch=132, lrate=1.000, error=0.044\n",
      ">epoch=133, lrate=1.000, error=0.044\n",
      ">epoch=134, lrate=1.000, error=0.043\n",
      ">epoch=135, lrate=1.000, error=0.043\n",
      ">epoch=136, lrate=1.000, error=0.042\n",
      ">epoch=137, lrate=1.000, error=0.042\n",
      ">epoch=138, lrate=1.000, error=0.042\n",
      ">epoch=139, lrate=1.000, error=0.041\n",
      ">epoch=140, lrate=1.000, error=0.041\n",
      ">epoch=141, lrate=1.000, error=0.041\n",
      ">epoch=142, lrate=1.000, error=0.040\n",
      ">epoch=143, lrate=1.000, error=0.040\n",
      ">epoch=144, lrate=1.000, error=0.040\n",
      ">epoch=145, lrate=1.000, error=0.039\n",
      ">epoch=146, lrate=1.000, error=0.039\n",
      ">epoch=147, lrate=1.000, error=0.039\n",
      ">epoch=148, lrate=1.000, error=0.039\n",
      ">epoch=149, lrate=1.000, error=0.038\n",
      ">epoch=150, lrate=1.000, error=0.038\n",
      ">epoch=151, lrate=1.000, error=0.038\n",
      ">epoch=152, lrate=1.000, error=0.037\n",
      ">epoch=153, lrate=1.000, error=0.037\n",
      ">epoch=154, lrate=1.000, error=0.037\n",
      ">epoch=155, lrate=1.000, error=0.037\n",
      ">epoch=156, lrate=1.000, error=0.036\n",
      ">epoch=157, lrate=1.000, error=0.036\n",
      ">epoch=158, lrate=1.000, error=0.036\n",
      ">epoch=159, lrate=1.000, error=0.035\n",
      ">epoch=160, lrate=1.000, error=0.035\n",
      ">epoch=161, lrate=1.000, error=0.035\n",
      ">epoch=162, lrate=1.000, error=0.035\n",
      ">epoch=163, lrate=1.000, error=0.034\n",
      ">epoch=164, lrate=1.000, error=0.034\n",
      ">epoch=165, lrate=1.000, error=0.034\n",
      ">epoch=166, lrate=1.000, error=0.034\n",
      ">epoch=167, lrate=1.000, error=0.034\n",
      ">epoch=168, lrate=1.000, error=0.033\n",
      ">epoch=169, lrate=1.000, error=0.033\n",
      ">epoch=170, lrate=1.000, error=0.033\n",
      ">epoch=171, lrate=1.000, error=0.033\n",
      ">epoch=172, lrate=1.000, error=0.032\n",
      ">epoch=173, lrate=1.000, error=0.032\n",
      ">epoch=174, lrate=1.000, error=0.032\n",
      ">epoch=175, lrate=1.000, error=0.032\n",
      ">epoch=176, lrate=1.000, error=0.032\n",
      ">epoch=177, lrate=1.000, error=0.031\n",
      ">epoch=178, lrate=1.000, error=0.031\n",
      ">epoch=179, lrate=1.000, error=0.031\n",
      ">epoch=180, lrate=1.000, error=0.031\n",
      ">epoch=181, lrate=1.000, error=0.031\n",
      ">epoch=182, lrate=1.000, error=0.030\n",
      ">epoch=183, lrate=1.000, error=0.030\n",
      ">epoch=184, lrate=1.000, error=0.030\n",
      ">epoch=185, lrate=1.000, error=0.030\n",
      ">epoch=186, lrate=1.000, error=0.030\n",
      ">epoch=187, lrate=1.000, error=0.030\n",
      ">epoch=188, lrate=1.000, error=0.029\n",
      ">epoch=189, lrate=1.000, error=0.029\n",
      ">epoch=190, lrate=1.000, error=0.029\n",
      ">epoch=191, lrate=1.000, error=0.029\n",
      ">epoch=192, lrate=1.000, error=0.029\n",
      ">epoch=193, lrate=1.000, error=0.028\n",
      ">epoch=194, lrate=1.000, error=0.028\n",
      ">epoch=195, lrate=1.000, error=0.028\n",
      ">epoch=196, lrate=1.000, error=0.028\n",
      ">epoch=197, lrate=1.000, error=0.028\n",
      ">epoch=198, lrate=1.000, error=0.028\n",
      ">epoch=199, lrate=1.000, error=0.028\n",
      ">epoch=200, lrate=1.000, error=0.027\n",
      ">epoch=201, lrate=1.000, error=0.027\n",
      ">epoch=202, lrate=1.000, error=0.027\n",
      ">epoch=203, lrate=1.000, error=0.027\n",
      ">epoch=204, lrate=1.000, error=0.027\n",
      ">epoch=205, lrate=1.000, error=0.027\n",
      ">epoch=206, lrate=1.000, error=0.026\n",
      ">epoch=207, lrate=1.000, error=0.026\n",
      ">epoch=208, lrate=1.000, error=0.026\n",
      ">epoch=209, lrate=1.000, error=0.026\n",
      ">epoch=210, lrate=1.000, error=0.026\n",
      ">epoch=211, lrate=1.000, error=0.026\n",
      ">epoch=212, lrate=1.000, error=0.026\n",
      ">epoch=213, lrate=1.000, error=0.025\n",
      ">epoch=214, lrate=1.000, error=0.025\n",
      ">epoch=215, lrate=1.000, error=0.025\n",
      ">epoch=216, lrate=1.000, error=0.025\n",
      ">epoch=217, lrate=1.000, error=0.025\n",
      ">epoch=218, lrate=1.000, error=0.025\n",
      ">epoch=219, lrate=1.000, error=0.025\n",
      ">epoch=220, lrate=1.000, error=0.025\n",
      ">epoch=221, lrate=1.000, error=0.024\n",
      ">epoch=222, lrate=1.000, error=0.024\n",
      ">epoch=223, lrate=1.000, error=0.024\n",
      ">epoch=224, lrate=1.000, error=0.024\n",
      ">epoch=225, lrate=1.000, error=0.024\n",
      ">epoch=226, lrate=1.000, error=0.024\n",
      ">epoch=227, lrate=1.000, error=0.024\n",
      ">epoch=228, lrate=1.000, error=0.024\n",
      ">epoch=229, lrate=1.000, error=0.024\n",
      ">epoch=230, lrate=1.000, error=0.023\n",
      ">epoch=231, lrate=1.000, error=0.023\n",
      ">epoch=232, lrate=1.000, error=0.023\n",
      ">epoch=233, lrate=1.000, error=0.023\n",
      ">epoch=234, lrate=1.000, error=0.023\n",
      ">epoch=235, lrate=1.000, error=0.023\n",
      ">epoch=236, lrate=1.000, error=0.023\n",
      ">epoch=237, lrate=1.000, error=0.023\n",
      ">epoch=238, lrate=1.000, error=0.023\n",
      ">epoch=239, lrate=1.000, error=0.022\n",
      ">epoch=240, lrate=1.000, error=0.022\n",
      ">epoch=241, lrate=1.000, error=0.022\n",
      ">epoch=242, lrate=1.000, error=0.022\n",
      ">epoch=243, lrate=1.000, error=0.022\n",
      ">epoch=244, lrate=1.000, error=0.022\n",
      ">epoch=245, lrate=1.000, error=0.022\n",
      ">epoch=246, lrate=1.000, error=0.022\n",
      ">epoch=247, lrate=1.000, error=0.022\n",
      ">epoch=248, lrate=1.000, error=0.022\n",
      ">epoch=249, lrate=1.000, error=0.021\n",
      ">epoch=250, lrate=1.000, error=0.021\n",
      ">epoch=251, lrate=1.000, error=0.021\n",
      ">epoch=252, lrate=1.000, error=0.021\n",
      ">epoch=253, lrate=1.000, error=0.021\n",
      ">epoch=254, lrate=1.000, error=0.021\n",
      ">epoch=255, lrate=1.000, error=0.021\n",
      ">epoch=256, lrate=1.000, error=0.021\n",
      ">epoch=257, lrate=1.000, error=0.021\n",
      ">epoch=258, lrate=1.000, error=0.021\n",
      ">epoch=259, lrate=1.000, error=0.021\n",
      ">epoch=260, lrate=1.000, error=0.020\n",
      ">epoch=261, lrate=1.000, error=0.020\n",
      ">epoch=262, lrate=1.000, error=0.020\n",
      ">epoch=263, lrate=1.000, error=0.020\n",
      ">epoch=264, lrate=1.000, error=0.020\n",
      ">epoch=265, lrate=1.000, error=0.020\n",
      ">epoch=266, lrate=1.000, error=0.020\n",
      ">epoch=267, lrate=1.000, error=0.020\n",
      ">epoch=268, lrate=1.000, error=0.020\n",
      ">epoch=269, lrate=1.000, error=0.020\n",
      ">epoch=270, lrate=1.000, error=0.020\n",
      ">epoch=271, lrate=1.000, error=0.020\n",
      ">epoch=272, lrate=1.000, error=0.019\n",
      ">epoch=273, lrate=1.000, error=0.019\n",
      ">epoch=274, lrate=1.000, error=0.019\n",
      ">epoch=275, lrate=1.000, error=0.019\n",
      ">epoch=276, lrate=1.000, error=0.019\n",
      ">epoch=277, lrate=1.000, error=0.019\n",
      ">epoch=278, lrate=1.000, error=0.019\n",
      ">epoch=279, lrate=1.000, error=0.019\n",
      ">epoch=280, lrate=1.000, error=0.019\n",
      ">epoch=281, lrate=1.000, error=0.019\n",
      ">epoch=282, lrate=1.000, error=0.019\n",
      ">epoch=283, lrate=1.000, error=0.019\n",
      ">epoch=284, lrate=1.000, error=0.019\n",
      ">epoch=285, lrate=1.000, error=0.018\n",
      ">epoch=286, lrate=1.000, error=0.018\n",
      ">epoch=287, lrate=1.000, error=0.018\n",
      ">epoch=288, lrate=1.000, error=0.018\n",
      ">epoch=289, lrate=1.000, error=0.018\n",
      ">epoch=290, lrate=1.000, error=0.018\n",
      ">epoch=291, lrate=1.000, error=0.018\n",
      ">epoch=292, lrate=1.000, error=0.018\n",
      ">epoch=293, lrate=1.000, error=0.018\n",
      ">epoch=294, lrate=1.000, error=0.018\n",
      ">epoch=295, lrate=1.000, error=0.018\n",
      ">epoch=296, lrate=1.000, error=0.018\n",
      ">epoch=297, lrate=1.000, error=0.018\n",
      ">epoch=298, lrate=1.000, error=0.018\n",
      ">epoch=299, lrate=1.000, error=0.018\n",
      ">epoch=300, lrate=1.000, error=0.017\n",
      ">epoch=301, lrate=1.000, error=0.017\n",
      ">epoch=302, lrate=1.000, error=0.017\n",
      ">epoch=303, lrate=1.000, error=0.017\n",
      ">epoch=304, lrate=1.000, error=0.017\n",
      ">epoch=305, lrate=1.000, error=0.017\n",
      ">epoch=306, lrate=1.000, error=0.017\n",
      ">epoch=307, lrate=1.000, error=0.017\n",
      ">epoch=308, lrate=1.000, error=0.017\n",
      ">epoch=309, lrate=1.000, error=0.017\n",
      ">epoch=310, lrate=1.000, error=0.017\n",
      ">epoch=311, lrate=1.000, error=0.017\n",
      ">epoch=312, lrate=1.000, error=0.017\n",
      ">epoch=313, lrate=1.000, error=0.017\n",
      ">epoch=314, lrate=1.000, error=0.017\n",
      ">epoch=315, lrate=1.000, error=0.017\n",
      ">epoch=316, lrate=1.000, error=0.017\n",
      ">epoch=317, lrate=1.000, error=0.016\n",
      ">epoch=318, lrate=1.000, error=0.016\n",
      ">epoch=319, lrate=1.000, error=0.016\n",
      ">epoch=320, lrate=1.000, error=0.016\n",
      ">epoch=321, lrate=1.000, error=0.016\n",
      ">epoch=322, lrate=1.000, error=0.016\n",
      ">epoch=323, lrate=1.000, error=0.016\n",
      ">epoch=324, lrate=1.000, error=0.016\n",
      ">epoch=325, lrate=1.000, error=0.016\n",
      ">epoch=326, lrate=1.000, error=0.016\n",
      ">epoch=327, lrate=1.000, error=0.016\n",
      ">epoch=328, lrate=1.000, error=0.016\n",
      ">epoch=329, lrate=1.000, error=0.016\n",
      ">epoch=330, lrate=1.000, error=0.016\n",
      ">epoch=331, lrate=1.000, error=0.016\n",
      ">epoch=332, lrate=1.000, error=0.016\n",
      ">epoch=333, lrate=1.000, error=0.016\n",
      ">epoch=334, lrate=1.000, error=0.016\n",
      ">epoch=335, lrate=1.000, error=0.015\n",
      ">epoch=336, lrate=1.000, error=0.015\n",
      ">epoch=337, lrate=1.000, error=0.015\n",
      ">epoch=338, lrate=1.000, error=0.015\n",
      ">epoch=339, lrate=1.000, error=0.015\n",
      ">epoch=340, lrate=1.000, error=0.015\n",
      ">epoch=341, lrate=1.000, error=0.015\n",
      ">epoch=342, lrate=1.000, error=0.015\n",
      ">epoch=343, lrate=1.000, error=0.015\n",
      ">epoch=344, lrate=1.000, error=0.015\n",
      ">epoch=345, lrate=1.000, error=0.015\n",
      ">epoch=346, lrate=1.000, error=0.015\n",
      ">epoch=347, lrate=1.000, error=0.015\n",
      ">epoch=348, lrate=1.000, error=0.015\n",
      ">epoch=349, lrate=1.000, error=0.015\n",
      ">epoch=350, lrate=1.000, error=0.015\n",
      ">epoch=351, lrate=1.000, error=0.015\n",
      ">epoch=352, lrate=1.000, error=0.015\n",
      ">epoch=353, lrate=1.000, error=0.015\n",
      ">epoch=354, lrate=1.000, error=0.015\n",
      ">epoch=355, lrate=1.000, error=0.015\n",
      ">epoch=356, lrate=1.000, error=0.014\n",
      ">epoch=357, lrate=1.000, error=0.014\n",
      ">epoch=358, lrate=1.000, error=0.014\n",
      ">epoch=359, lrate=1.000, error=0.014\n",
      ">epoch=360, lrate=1.000, error=0.014\n",
      ">epoch=361, lrate=1.000, error=0.014\n",
      ">epoch=362, lrate=1.000, error=0.014\n",
      ">epoch=363, lrate=1.000, error=0.014\n",
      ">epoch=364, lrate=1.000, error=0.014\n",
      ">epoch=365, lrate=1.000, error=0.014\n",
      ">epoch=366, lrate=1.000, error=0.014\n",
      ">epoch=367, lrate=1.000, error=0.014\n",
      ">epoch=368, lrate=1.000, error=0.014\n",
      ">epoch=369, lrate=1.000, error=0.014\n",
      ">epoch=370, lrate=1.000, error=0.014\n",
      ">epoch=371, lrate=1.000, error=0.014\n",
      ">epoch=372, lrate=1.000, error=0.014\n",
      ">epoch=373, lrate=1.000, error=0.014\n",
      ">epoch=374, lrate=1.000, error=0.014\n",
      ">epoch=375, lrate=1.000, error=0.014\n",
      ">epoch=376, lrate=1.000, error=0.014\n",
      ">epoch=377, lrate=1.000, error=0.014\n",
      ">epoch=378, lrate=1.000, error=0.014\n",
      ">epoch=379, lrate=1.000, error=0.014\n",
      ">epoch=380, lrate=1.000, error=0.014\n",
      ">epoch=381, lrate=1.000, error=0.013\n",
      ">epoch=382, lrate=1.000, error=0.013\n",
      ">epoch=383, lrate=1.000, error=0.013\n",
      ">epoch=384, lrate=1.000, error=0.013\n",
      ">epoch=385, lrate=1.000, error=0.013\n",
      ">epoch=386, lrate=1.000, error=0.013\n",
      ">epoch=387, lrate=1.000, error=0.013\n",
      ">epoch=388, lrate=1.000, error=0.013\n",
      ">epoch=389, lrate=1.000, error=0.013\n",
      ">epoch=390, lrate=1.000, error=0.013\n",
      ">epoch=391, lrate=1.000, error=0.013\n",
      ">epoch=392, lrate=1.000, error=0.013\n",
      ">epoch=393, lrate=1.000, error=0.013\n",
      ">epoch=394, lrate=1.000, error=0.013\n",
      ">epoch=395, lrate=1.000, error=0.013\n",
      ">epoch=396, lrate=1.000, error=0.013\n",
      ">epoch=397, lrate=1.000, error=0.013\n",
      ">epoch=398, lrate=1.000, error=0.013\n",
      ">epoch=399, lrate=1.000, error=0.013\n",
      ">epoch=400, lrate=1.000, error=0.013\n",
      ">epoch=401, lrate=1.000, error=0.013\n",
      ">epoch=402, lrate=1.000, error=0.013\n",
      ">epoch=403, lrate=1.000, error=0.013\n",
      ">epoch=404, lrate=1.000, error=0.013\n",
      ">epoch=405, lrate=1.000, error=0.013\n",
      ">epoch=406, lrate=1.000, error=0.013\n",
      ">epoch=407, lrate=1.000, error=0.013\n",
      ">epoch=408, lrate=1.000, error=0.013\n",
      ">epoch=409, lrate=1.000, error=0.012\n",
      ">epoch=410, lrate=1.000, error=0.012\n",
      ">epoch=411, lrate=1.000, error=0.012\n",
      ">epoch=412, lrate=1.000, error=0.012\n",
      ">epoch=413, lrate=1.000, error=0.012\n",
      ">epoch=414, lrate=1.000, error=0.012\n",
      ">epoch=415, lrate=1.000, error=0.012\n",
      ">epoch=416, lrate=1.000, error=0.012\n",
      ">epoch=417, lrate=1.000, error=0.012\n",
      ">epoch=418, lrate=1.000, error=0.012\n",
      ">epoch=419, lrate=1.000, error=0.012\n",
      ">epoch=420, lrate=1.000, error=0.012\n",
      ">epoch=421, lrate=1.000, error=0.012\n",
      ">epoch=422, lrate=1.000, error=0.012\n",
      ">epoch=423, lrate=1.000, error=0.012\n",
      ">epoch=424, lrate=1.000, error=0.012\n",
      ">epoch=425, lrate=1.000, error=0.012\n",
      ">epoch=426, lrate=1.000, error=0.012\n",
      ">epoch=427, lrate=1.000, error=0.012\n",
      ">epoch=428, lrate=1.000, error=0.012\n",
      ">epoch=429, lrate=1.000, error=0.012\n",
      ">epoch=430, lrate=1.000, error=0.012\n",
      ">epoch=431, lrate=1.000, error=0.012\n",
      ">epoch=432, lrate=1.000, error=0.012\n",
      ">epoch=433, lrate=1.000, error=0.012\n",
      ">epoch=434, lrate=1.000, error=0.012\n",
      ">epoch=435, lrate=1.000, error=0.012\n",
      ">epoch=436, lrate=1.000, error=0.012\n",
      ">epoch=437, lrate=1.000, error=0.012\n",
      ">epoch=438, lrate=1.000, error=0.012\n",
      ">epoch=439, lrate=1.000, error=0.012\n",
      ">epoch=440, lrate=1.000, error=0.012\n",
      ">epoch=441, lrate=1.000, error=0.012\n",
      ">epoch=442, lrate=1.000, error=0.011\n",
      ">epoch=443, lrate=1.000, error=0.011\n",
      ">epoch=444, lrate=1.000, error=0.011\n",
      ">epoch=445, lrate=1.000, error=0.011\n",
      ">epoch=446, lrate=1.000, error=0.011\n",
      ">epoch=447, lrate=1.000, error=0.011\n",
      ">epoch=448, lrate=1.000, error=0.011\n",
      ">epoch=449, lrate=1.000, error=0.011\n",
      ">epoch=450, lrate=1.000, error=0.011\n",
      ">epoch=451, lrate=1.000, error=0.011\n",
      ">epoch=452, lrate=1.000, error=0.011\n",
      ">epoch=453, lrate=1.000, error=0.011\n",
      ">epoch=454, lrate=1.000, error=0.011\n",
      ">epoch=455, lrate=1.000, error=0.011\n",
      ">epoch=456, lrate=1.000, error=0.011\n",
      ">epoch=457, lrate=1.000, error=0.011\n",
      ">epoch=458, lrate=1.000, error=0.011\n",
      ">epoch=459, lrate=1.000, error=0.011\n",
      ">epoch=460, lrate=1.000, error=0.011\n",
      ">epoch=461, lrate=1.000, error=0.011\n",
      ">epoch=462, lrate=1.000, error=0.011\n",
      ">epoch=463, lrate=1.000, error=0.011\n",
      ">epoch=464, lrate=1.000, error=0.011\n",
      ">epoch=465, lrate=1.000, error=0.011\n",
      ">epoch=466, lrate=1.000, error=0.011\n",
      ">epoch=467, lrate=1.000, error=0.011\n",
      ">epoch=468, lrate=1.000, error=0.011\n",
      ">epoch=469, lrate=1.000, error=0.011\n",
      ">epoch=470, lrate=1.000, error=0.011\n",
      ">epoch=471, lrate=1.000, error=0.011\n",
      ">epoch=472, lrate=1.000, error=0.011\n",
      ">epoch=473, lrate=1.000, error=0.011\n",
      ">epoch=474, lrate=1.000, error=0.011\n",
      ">epoch=475, lrate=1.000, error=0.011\n",
      ">epoch=476, lrate=1.000, error=0.011\n",
      ">epoch=477, lrate=1.000, error=0.011\n",
      ">epoch=478, lrate=1.000, error=0.011\n",
      ">epoch=479, lrate=1.000, error=0.011\n",
      ">epoch=480, lrate=1.000, error=0.011\n",
      ">epoch=481, lrate=1.000, error=0.010\n",
      ">epoch=482, lrate=1.000, error=0.010\n",
      ">epoch=483, lrate=1.000, error=0.010\n",
      ">epoch=484, lrate=1.000, error=0.010\n",
      ">epoch=485, lrate=1.000, error=0.010\n",
      ">epoch=486, lrate=1.000, error=0.010\n",
      ">epoch=487, lrate=1.000, error=0.010\n",
      ">epoch=488, lrate=1.000, error=0.010\n",
      ">epoch=489, lrate=1.000, error=0.010\n",
      ">epoch=490, lrate=1.000, error=0.010\n",
      ">epoch=491, lrate=1.000, error=0.010\n",
      ">epoch=492, lrate=1.000, error=0.010\n",
      ">epoch=493, lrate=1.000, error=0.010\n",
      ">epoch=494, lrate=1.000, error=0.010\n",
      ">epoch=495, lrate=1.000, error=0.010\n",
      ">epoch=496, lrate=1.000, error=0.010\n",
      ">epoch=497, lrate=1.000, error=0.010\n",
      ">epoch=498, lrate=1.000, error=0.010\n",
      ">epoch=499, lrate=1.000, error=0.010\n",
      ">epoch=500, lrate=1.000, error=0.010\n",
      ">epoch=501, lrate=1.000, error=0.010\n",
      ">epoch=502, lrate=1.000, error=0.010\n",
      ">epoch=503, lrate=1.000, error=0.010\n",
      ">epoch=504, lrate=1.000, error=0.010\n",
      ">epoch=505, lrate=1.000, error=0.010\n",
      ">epoch=506, lrate=1.000, error=0.010\n",
      ">epoch=507, lrate=1.000, error=0.010\n",
      ">epoch=508, lrate=1.000, error=0.010\n",
      ">epoch=509, lrate=1.000, error=0.010\n",
      ">epoch=510, lrate=1.000, error=0.010\n",
      ">epoch=511, lrate=1.000, error=0.010\n",
      ">epoch=512, lrate=1.000, error=0.010\n",
      ">epoch=513, lrate=1.000, error=0.010\n",
      ">epoch=514, lrate=1.000, error=0.010\n",
      ">epoch=515, lrate=1.000, error=0.010\n",
      ">epoch=516, lrate=1.000, error=0.010\n",
      ">epoch=517, lrate=1.000, error=0.010\n",
      ">epoch=518, lrate=1.000, error=0.010\n",
      ">epoch=519, lrate=1.000, error=0.010\n",
      ">epoch=520, lrate=1.000, error=0.010\n",
      ">epoch=521, lrate=1.000, error=0.010\n",
      ">epoch=522, lrate=1.000, error=0.010\n",
      ">epoch=523, lrate=1.000, error=0.010\n",
      ">epoch=524, lrate=1.000, error=0.010\n",
      ">epoch=525, lrate=1.000, error=0.010\n",
      ">epoch=526, lrate=1.000, error=0.010\n",
      ">epoch=527, lrate=1.000, error=0.010\n",
      ">epoch=528, lrate=1.000, error=0.010\n",
      ">epoch=529, lrate=1.000, error=0.009\n",
      ">epoch=530, lrate=1.000, error=0.009\n",
      ">epoch=531, lrate=1.000, error=0.009\n",
      ">epoch=532, lrate=1.000, error=0.009\n",
      ">epoch=533, lrate=1.000, error=0.009\n",
      ">epoch=534, lrate=1.000, error=0.009\n",
      ">epoch=535, lrate=1.000, error=0.009\n",
      ">epoch=536, lrate=1.000, error=0.009\n",
      ">epoch=537, lrate=1.000, error=0.009\n",
      ">epoch=538, lrate=1.000, error=0.009\n",
      ">epoch=539, lrate=1.000, error=0.009\n",
      ">epoch=540, lrate=1.000, error=0.009\n",
      ">epoch=541, lrate=1.000, error=0.009\n",
      ">epoch=542, lrate=1.000, error=0.009\n",
      ">epoch=543, lrate=1.000, error=0.009\n",
      ">epoch=544, lrate=1.000, error=0.009\n",
      ">epoch=545, lrate=1.000, error=0.009\n",
      ">epoch=546, lrate=1.000, error=0.009\n",
      ">epoch=547, lrate=1.000, error=0.009\n",
      ">epoch=548, lrate=1.000, error=0.009\n",
      ">epoch=549, lrate=1.000, error=0.009\n",
      ">epoch=550, lrate=1.000, error=0.009\n",
      ">epoch=551, lrate=1.000, error=0.009\n",
      ">epoch=552, lrate=1.000, error=0.009\n",
      ">epoch=553, lrate=1.000, error=0.009\n",
      ">epoch=554, lrate=1.000, error=0.009\n",
      ">epoch=555, lrate=1.000, error=0.009\n",
      ">epoch=556, lrate=1.000, error=0.009\n",
      ">epoch=557, lrate=1.000, error=0.009\n",
      ">epoch=558, lrate=1.000, error=0.009\n",
      ">epoch=559, lrate=1.000, error=0.009\n",
      ">epoch=560, lrate=1.000, error=0.009\n",
      ">epoch=561, lrate=1.000, error=0.009\n",
      ">epoch=562, lrate=1.000, error=0.009\n",
      ">epoch=563, lrate=1.000, error=0.009\n",
      ">epoch=564, lrate=1.000, error=0.009\n",
      ">epoch=565, lrate=1.000, error=0.009\n",
      ">epoch=566, lrate=1.000, error=0.009\n",
      ">epoch=567, lrate=1.000, error=0.009\n",
      ">epoch=568, lrate=1.000, error=0.009\n",
      ">epoch=569, lrate=1.000, error=0.009\n",
      ">epoch=570, lrate=1.000, error=0.009\n",
      ">epoch=571, lrate=1.000, error=0.009\n",
      ">epoch=572, lrate=1.000, error=0.009\n",
      ">epoch=573, lrate=1.000, error=0.009\n",
      ">epoch=574, lrate=1.000, error=0.009\n",
      ">epoch=575, lrate=1.000, error=0.009\n",
      ">epoch=576, lrate=1.000, error=0.009\n",
      ">epoch=577, lrate=1.000, error=0.009\n",
      ">epoch=578, lrate=1.000, error=0.009\n",
      ">epoch=579, lrate=1.000, error=0.009\n",
      ">epoch=580, lrate=1.000, error=0.009\n",
      ">epoch=581, lrate=1.000, error=0.009\n",
      ">epoch=582, lrate=1.000, error=0.009\n",
      ">epoch=583, lrate=1.000, error=0.009\n",
      ">epoch=584, lrate=1.000, error=0.009\n",
      ">epoch=585, lrate=1.000, error=0.009\n",
      ">epoch=586, lrate=1.000, error=0.009\n",
      ">epoch=587, lrate=1.000, error=0.008\n",
      ">epoch=588, lrate=1.000, error=0.008\n",
      ">epoch=589, lrate=1.000, error=0.008\n",
      ">epoch=590, lrate=1.000, error=0.008\n",
      ">epoch=591, lrate=1.000, error=0.008\n",
      ">epoch=592, lrate=1.000, error=0.008\n",
      ">epoch=593, lrate=1.000, error=0.008\n",
      ">epoch=594, lrate=1.000, error=0.008\n",
      ">epoch=595, lrate=1.000, error=0.008\n",
      ">epoch=596, lrate=1.000, error=0.008\n",
      ">epoch=597, lrate=1.000, error=0.008\n",
      ">epoch=598, lrate=1.000, error=0.008\n",
      ">epoch=599, lrate=1.000, error=0.008\n",
      ">epoch=600, lrate=1.000, error=0.008\n",
      ">epoch=601, lrate=1.000, error=0.008\n",
      ">epoch=602, lrate=1.000, error=0.008\n",
      ">epoch=603, lrate=1.000, error=0.008\n",
      ">epoch=604, lrate=1.000, error=0.008\n",
      ">epoch=605, lrate=1.000, error=0.008\n",
      ">epoch=606, lrate=1.000, error=0.008\n",
      ">epoch=607, lrate=1.000, error=0.008\n",
      ">epoch=608, lrate=1.000, error=0.008\n",
      ">epoch=609, lrate=1.000, error=0.008\n",
      ">epoch=610, lrate=1.000, error=0.008\n",
      ">epoch=611, lrate=1.000, error=0.008\n",
      ">epoch=612, lrate=1.000, error=0.008\n",
      ">epoch=613, lrate=1.000, error=0.008\n",
      ">epoch=614, lrate=1.000, error=0.008\n",
      ">epoch=615, lrate=1.000, error=0.008\n",
      ">epoch=616, lrate=1.000, error=0.008\n",
      ">epoch=617, lrate=1.000, error=0.008\n",
      ">epoch=618, lrate=1.000, error=0.008\n",
      ">epoch=619, lrate=1.000, error=0.008\n",
      ">epoch=620, lrate=1.000, error=0.008\n",
      ">epoch=621, lrate=1.000, error=0.008\n",
      ">epoch=622, lrate=1.000, error=0.008\n",
      ">epoch=623, lrate=1.000, error=0.008\n",
      ">epoch=624, lrate=1.000, error=0.008\n",
      ">epoch=625, lrate=1.000, error=0.008\n",
      ">epoch=626, lrate=1.000, error=0.008\n",
      ">epoch=627, lrate=1.000, error=0.008\n",
      ">epoch=628, lrate=1.000, error=0.008\n",
      ">epoch=629, lrate=1.000, error=0.008\n",
      ">epoch=630, lrate=1.000, error=0.008\n",
      ">epoch=631, lrate=1.000, error=0.008\n",
      ">epoch=632, lrate=1.000, error=0.008\n",
      ">epoch=633, lrate=1.000, error=0.008\n",
      ">epoch=634, lrate=1.000, error=0.008\n",
      ">epoch=635, lrate=1.000, error=0.008\n",
      ">epoch=636, lrate=1.000, error=0.008\n",
      ">epoch=637, lrate=1.000, error=0.008\n",
      ">epoch=638, lrate=1.000, error=0.008\n",
      ">epoch=639, lrate=1.000, error=0.008\n",
      ">epoch=640, lrate=1.000, error=0.008\n",
      ">epoch=641, lrate=1.000, error=0.008\n",
      ">epoch=642, lrate=1.000, error=0.008\n",
      ">epoch=643, lrate=1.000, error=0.008\n",
      ">epoch=644, lrate=1.000, error=0.008\n",
      ">epoch=645, lrate=1.000, error=0.008\n",
      ">epoch=646, lrate=1.000, error=0.008\n",
      ">epoch=647, lrate=1.000, error=0.008\n",
      ">epoch=648, lrate=1.000, error=0.008\n",
      ">epoch=649, lrate=1.000, error=0.008\n",
      ">epoch=650, lrate=1.000, error=0.008\n",
      ">epoch=651, lrate=1.000, error=0.008\n",
      ">epoch=652, lrate=1.000, error=0.008\n",
      ">epoch=653, lrate=1.000, error=0.008\n",
      ">epoch=654, lrate=1.000, error=0.008\n",
      ">epoch=655, lrate=1.000, error=0.008\n",
      ">epoch=656, lrate=1.000, error=0.008\n",
      ">epoch=657, lrate=1.000, error=0.008\n",
      ">epoch=658, lrate=1.000, error=0.008\n",
      ">epoch=659, lrate=1.000, error=0.008\n",
      ">epoch=660, lrate=1.000, error=0.008\n",
      ">epoch=661, lrate=1.000, error=0.007\n",
      ">epoch=662, lrate=1.000, error=0.007\n",
      ">epoch=663, lrate=1.000, error=0.007\n",
      ">epoch=664, lrate=1.000, error=0.007\n",
      ">epoch=665, lrate=1.000, error=0.007\n",
      ">epoch=666, lrate=1.000, error=0.007\n",
      ">epoch=667, lrate=1.000, error=0.007\n",
      ">epoch=668, lrate=1.000, error=0.007\n",
      ">epoch=669, lrate=1.000, error=0.007\n",
      ">epoch=670, lrate=1.000, error=0.007\n",
      ">epoch=671, lrate=1.000, error=0.007\n",
      ">epoch=672, lrate=1.000, error=0.007\n",
      ">epoch=673, lrate=1.000, error=0.007\n",
      ">epoch=674, lrate=1.000, error=0.007\n",
      ">epoch=675, lrate=1.000, error=0.007\n",
      ">epoch=676, lrate=1.000, error=0.007\n",
      ">epoch=677, lrate=1.000, error=0.007\n",
      ">epoch=678, lrate=1.000, error=0.007\n",
      ">epoch=679, lrate=1.000, error=0.007\n",
      ">epoch=680, lrate=1.000, error=0.007\n",
      ">epoch=681, lrate=1.000, error=0.007\n",
      ">epoch=682, lrate=1.000, error=0.007\n",
      ">epoch=683, lrate=1.000, error=0.007\n",
      ">epoch=684, lrate=1.000, error=0.007\n",
      ">epoch=685, lrate=1.000, error=0.007\n",
      ">epoch=686, lrate=1.000, error=0.007\n",
      ">epoch=687, lrate=1.000, error=0.007\n",
      ">epoch=688, lrate=1.000, error=0.007\n",
      ">epoch=689, lrate=1.000, error=0.007\n",
      ">epoch=690, lrate=1.000, error=0.007\n",
      ">epoch=691, lrate=1.000, error=0.007\n",
      ">epoch=692, lrate=1.000, error=0.007\n",
      ">epoch=693, lrate=1.000, error=0.007\n",
      ">epoch=694, lrate=1.000, error=0.007\n",
      ">epoch=695, lrate=1.000, error=0.007\n",
      ">epoch=696, lrate=1.000, error=0.007\n",
      ">epoch=697, lrate=1.000, error=0.007\n",
      ">epoch=698, lrate=1.000, error=0.007\n",
      ">epoch=699, lrate=1.000, error=0.007\n",
      ">epoch=700, lrate=1.000, error=0.007\n",
      ">epoch=701, lrate=1.000, error=0.007\n",
      ">epoch=702, lrate=1.000, error=0.007\n",
      ">epoch=703, lrate=1.000, error=0.007\n",
      ">epoch=704, lrate=1.000, error=0.007\n",
      ">epoch=705, lrate=1.000, error=0.007\n",
      ">epoch=706, lrate=1.000, error=0.007\n",
      ">epoch=707, lrate=1.000, error=0.007\n",
      ">epoch=708, lrate=1.000, error=0.007\n",
      ">epoch=709, lrate=1.000, error=0.007\n",
      ">epoch=710, lrate=1.000, error=0.007\n",
      ">epoch=711, lrate=1.000, error=0.007\n",
      ">epoch=712, lrate=1.000, error=0.007\n",
      ">epoch=713, lrate=1.000, error=0.007\n",
      ">epoch=714, lrate=1.000, error=0.007\n",
      ">epoch=715, lrate=1.000, error=0.007\n",
      ">epoch=716, lrate=1.000, error=0.007\n",
      ">epoch=717, lrate=1.000, error=0.007\n",
      ">epoch=718, lrate=1.000, error=0.007\n",
      ">epoch=719, lrate=1.000, error=0.007\n",
      ">epoch=720, lrate=1.000, error=0.007\n",
      ">epoch=721, lrate=1.000, error=0.007\n",
      ">epoch=722, lrate=1.000, error=0.007\n",
      ">epoch=723, lrate=1.000, error=0.007\n",
      ">epoch=724, lrate=1.000, error=0.007\n",
      ">epoch=725, lrate=1.000, error=0.007\n",
      ">epoch=726, lrate=1.000, error=0.007\n",
      ">epoch=727, lrate=1.000, error=0.007\n",
      ">epoch=728, lrate=1.000, error=0.007\n",
      ">epoch=729, lrate=1.000, error=0.007\n",
      ">epoch=730, lrate=1.000, error=0.007\n",
      ">epoch=731, lrate=1.000, error=0.007\n",
      ">epoch=732, lrate=1.000, error=0.007\n",
      ">epoch=733, lrate=1.000, error=0.007\n",
      ">epoch=734, lrate=1.000, error=0.007\n",
      ">epoch=735, lrate=1.000, error=0.007\n",
      ">epoch=736, lrate=1.000, error=0.007\n",
      ">epoch=737, lrate=1.000, error=0.007\n",
      ">epoch=738, lrate=1.000, error=0.007\n",
      ">epoch=739, lrate=1.000, error=0.007\n",
      ">epoch=740, lrate=1.000, error=0.007\n",
      ">epoch=741, lrate=1.000, error=0.007\n",
      ">epoch=742, lrate=1.000, error=0.007\n",
      ">epoch=743, lrate=1.000, error=0.007\n",
      ">epoch=744, lrate=1.000, error=0.007\n",
      ">epoch=745, lrate=1.000, error=0.007\n",
      ">epoch=746, lrate=1.000, error=0.007\n",
      ">epoch=747, lrate=1.000, error=0.007\n",
      ">epoch=748, lrate=1.000, error=0.007\n",
      ">epoch=749, lrate=1.000, error=0.007\n",
      ">epoch=750, lrate=1.000, error=0.007\n",
      ">epoch=751, lrate=1.000, error=0.007\n",
      ">epoch=752, lrate=1.000, error=0.007\n",
      ">epoch=753, lrate=1.000, error=0.007\n",
      ">epoch=754, lrate=1.000, error=0.007\n",
      ">epoch=755, lrate=1.000, error=0.007\n",
      ">epoch=756, lrate=1.000, error=0.007\n",
      ">epoch=757, lrate=1.000, error=0.006\n",
      ">epoch=758, lrate=1.000, error=0.006\n",
      ">epoch=759, lrate=1.000, error=0.006\n",
      ">epoch=760, lrate=1.000, error=0.006\n",
      ">epoch=761, lrate=1.000, error=0.006\n",
      ">epoch=762, lrate=1.000, error=0.006\n",
      ">epoch=763, lrate=1.000, error=0.006\n",
      ">epoch=764, lrate=1.000, error=0.006\n",
      ">epoch=765, lrate=1.000, error=0.006\n",
      ">epoch=766, lrate=1.000, error=0.006\n",
      ">epoch=767, lrate=1.000, error=0.006\n",
      ">epoch=768, lrate=1.000, error=0.006\n",
      ">epoch=769, lrate=1.000, error=0.006\n",
      ">epoch=770, lrate=1.000, error=0.006\n",
      ">epoch=771, lrate=1.000, error=0.006\n",
      ">epoch=772, lrate=1.000, error=0.006\n",
      ">epoch=773, lrate=1.000, error=0.006\n",
      ">epoch=774, lrate=1.000, error=0.006\n",
      ">epoch=775, lrate=1.000, error=0.006\n",
      ">epoch=776, lrate=1.000, error=0.006\n",
      ">epoch=777, lrate=1.000, error=0.006\n",
      ">epoch=778, lrate=1.000, error=0.006\n",
      ">epoch=779, lrate=1.000, error=0.006\n",
      ">epoch=780, lrate=1.000, error=0.006\n",
      ">epoch=781, lrate=1.000, error=0.006\n",
      ">epoch=782, lrate=1.000, error=0.006\n",
      ">epoch=783, lrate=1.000, error=0.006\n",
      ">epoch=784, lrate=1.000, error=0.006\n",
      ">epoch=785, lrate=1.000, error=0.006\n",
      ">epoch=786, lrate=1.000, error=0.006\n",
      ">epoch=787, lrate=1.000, error=0.006\n",
      ">epoch=788, lrate=1.000, error=0.006\n",
      ">epoch=789, lrate=1.000, error=0.006\n",
      ">epoch=790, lrate=1.000, error=0.006\n",
      ">epoch=791, lrate=1.000, error=0.006\n",
      ">epoch=792, lrate=1.000, error=0.006\n",
      ">epoch=793, lrate=1.000, error=0.006\n",
      ">epoch=794, lrate=1.000, error=0.006\n",
      ">epoch=795, lrate=1.000, error=0.006\n",
      ">epoch=796, lrate=1.000, error=0.006\n",
      ">epoch=797, lrate=1.000, error=0.006\n",
      ">epoch=798, lrate=1.000, error=0.006\n",
      ">epoch=799, lrate=1.000, error=0.006\n",
      ">epoch=800, lrate=1.000, error=0.006\n",
      ">epoch=801, lrate=1.000, error=0.006\n",
      ">epoch=802, lrate=1.000, error=0.006\n",
      ">epoch=803, lrate=1.000, error=0.006\n",
      ">epoch=804, lrate=1.000, error=0.006\n",
      ">epoch=805, lrate=1.000, error=0.006\n",
      ">epoch=806, lrate=1.000, error=0.006\n",
      ">epoch=807, lrate=1.000, error=0.006\n",
      ">epoch=808, lrate=1.000, error=0.006\n",
      ">epoch=809, lrate=1.000, error=0.006\n",
      ">epoch=810, lrate=1.000, error=0.006\n",
      ">epoch=811, lrate=1.000, error=0.006\n",
      ">epoch=812, lrate=1.000, error=0.006\n",
      ">epoch=813, lrate=1.000, error=0.006\n",
      ">epoch=814, lrate=1.000, error=0.006\n",
      ">epoch=815, lrate=1.000, error=0.006\n",
      ">epoch=816, lrate=1.000, error=0.006\n",
      ">epoch=817, lrate=1.000, error=0.006\n",
      ">epoch=818, lrate=1.000, error=0.006\n",
      ">epoch=819, lrate=1.000, error=0.006\n",
      ">epoch=820, lrate=1.000, error=0.006\n",
      ">epoch=821, lrate=1.000, error=0.006\n",
      ">epoch=822, lrate=1.000, error=0.006\n",
      ">epoch=823, lrate=1.000, error=0.006\n",
      ">epoch=824, lrate=1.000, error=0.006\n",
      ">epoch=825, lrate=1.000, error=0.006\n",
      ">epoch=826, lrate=1.000, error=0.006\n",
      ">epoch=827, lrate=1.000, error=0.006\n",
      ">epoch=828, lrate=1.000, error=0.006\n",
      ">epoch=829, lrate=1.000, error=0.006\n",
      ">epoch=830, lrate=1.000, error=0.006\n",
      ">epoch=831, lrate=1.000, error=0.006\n",
      ">epoch=832, lrate=1.000, error=0.006\n",
      ">epoch=833, lrate=1.000, error=0.006\n",
      ">epoch=834, lrate=1.000, error=0.006\n",
      ">epoch=835, lrate=1.000, error=0.006\n",
      ">epoch=836, lrate=1.000, error=0.006\n",
      ">epoch=837, lrate=1.000, error=0.006\n",
      ">epoch=838, lrate=1.000, error=0.006\n",
      ">epoch=839, lrate=1.000, error=0.006\n",
      ">epoch=840, lrate=1.000, error=0.006\n",
      ">epoch=841, lrate=1.000, error=0.006\n",
      ">epoch=842, lrate=1.000, error=0.006\n",
      ">epoch=843, lrate=1.000, error=0.006\n",
      ">epoch=844, lrate=1.000, error=0.006\n",
      ">epoch=845, lrate=1.000, error=0.006\n",
      ">epoch=846, lrate=1.000, error=0.006\n",
      ">epoch=847, lrate=1.000, error=0.006\n",
      ">epoch=848, lrate=1.000, error=0.006\n",
      ">epoch=849, lrate=1.000, error=0.006\n",
      ">epoch=850, lrate=1.000, error=0.006\n",
      ">epoch=851, lrate=1.000, error=0.006\n",
      ">epoch=852, lrate=1.000, error=0.006\n",
      ">epoch=853, lrate=1.000, error=0.006\n",
      ">epoch=854, lrate=1.000, error=0.006\n",
      ">epoch=855, lrate=1.000, error=0.006\n",
      ">epoch=856, lrate=1.000, error=0.006\n",
      ">epoch=857, lrate=1.000, error=0.006\n",
      ">epoch=858, lrate=1.000, error=0.006\n",
      ">epoch=859, lrate=1.000, error=0.006\n",
      ">epoch=860, lrate=1.000, error=0.006\n",
      ">epoch=861, lrate=1.000, error=0.006\n",
      ">epoch=862, lrate=1.000, error=0.006\n",
      ">epoch=863, lrate=1.000, error=0.006\n",
      ">epoch=864, lrate=1.000, error=0.006\n",
      ">epoch=865, lrate=1.000, error=0.006\n",
      ">epoch=866, lrate=1.000, error=0.006\n",
      ">epoch=867, lrate=1.000, error=0.006\n",
      ">epoch=868, lrate=1.000, error=0.006\n",
      ">epoch=869, lrate=1.000, error=0.006\n",
      ">epoch=870, lrate=1.000, error=0.006\n",
      ">epoch=871, lrate=1.000, error=0.006\n",
      ">epoch=872, lrate=1.000, error=0.006\n",
      ">epoch=873, lrate=1.000, error=0.006\n",
      ">epoch=874, lrate=1.000, error=0.006\n",
      ">epoch=875, lrate=1.000, error=0.006\n",
      ">epoch=876, lrate=1.000, error=0.006\n",
      ">epoch=877, lrate=1.000, error=0.006\n",
      ">epoch=878, lrate=1.000, error=0.006\n",
      ">epoch=879, lrate=1.000, error=0.006\n",
      ">epoch=880, lrate=1.000, error=0.006\n",
      ">epoch=881, lrate=1.000, error=0.006\n",
      ">epoch=882, lrate=1.000, error=0.006\n",
      ">epoch=883, lrate=1.000, error=0.006\n",
      ">epoch=884, lrate=1.000, error=0.006\n",
      ">epoch=885, lrate=1.000, error=0.006\n",
      ">epoch=886, lrate=1.000, error=0.006\n",
      ">epoch=887, lrate=1.000, error=0.006\n",
      ">epoch=888, lrate=1.000, error=0.005\n",
      ">epoch=889, lrate=1.000, error=0.005\n",
      ">epoch=890, lrate=1.000, error=0.005\n",
      ">epoch=891, lrate=1.000, error=0.005\n",
      ">epoch=892, lrate=1.000, error=0.005\n",
      ">epoch=893, lrate=1.000, error=0.005\n",
      ">epoch=894, lrate=1.000, error=0.005\n",
      ">epoch=895, lrate=1.000, error=0.005\n",
      ">epoch=896, lrate=1.000, error=0.005\n",
      ">epoch=897, lrate=1.000, error=0.005\n",
      ">epoch=898, lrate=1.000, error=0.005\n",
      ">epoch=899, lrate=1.000, error=0.005\n",
      ">epoch=900, lrate=1.000, error=0.005\n",
      ">epoch=901, lrate=1.000, error=0.005\n",
      ">epoch=902, lrate=1.000, error=0.005\n",
      ">epoch=903, lrate=1.000, error=0.005\n",
      ">epoch=904, lrate=1.000, error=0.005\n",
      ">epoch=905, lrate=1.000, error=0.005\n",
      ">epoch=906, lrate=1.000, error=0.005\n",
      ">epoch=907, lrate=1.000, error=0.005\n",
      ">epoch=908, lrate=1.000, error=0.005\n",
      ">epoch=909, lrate=1.000, error=0.005\n",
      ">epoch=910, lrate=1.000, error=0.005\n",
      ">epoch=911, lrate=1.000, error=0.005\n",
      ">epoch=912, lrate=1.000, error=0.005\n",
      ">epoch=913, lrate=1.000, error=0.005\n",
      ">epoch=914, lrate=1.000, error=0.005\n",
      ">epoch=915, lrate=1.000, error=0.005\n",
      ">epoch=916, lrate=1.000, error=0.005\n",
      ">epoch=917, lrate=1.000, error=0.005\n",
      ">epoch=918, lrate=1.000, error=0.005\n",
      ">epoch=919, lrate=1.000, error=0.005\n",
      ">epoch=920, lrate=1.000, error=0.005\n",
      ">epoch=921, lrate=1.000, error=0.005\n",
      ">epoch=922, lrate=1.000, error=0.005\n",
      ">epoch=923, lrate=1.000, error=0.005\n",
      ">epoch=924, lrate=1.000, error=0.005\n",
      ">epoch=925, lrate=1.000, error=0.005\n",
      ">epoch=926, lrate=1.000, error=0.005\n",
      ">epoch=927, lrate=1.000, error=0.005\n",
      ">epoch=928, lrate=1.000, error=0.005\n",
      ">epoch=929, lrate=1.000, error=0.005\n",
      ">epoch=930, lrate=1.000, error=0.005\n",
      ">epoch=931, lrate=1.000, error=0.005\n",
      ">epoch=932, lrate=1.000, error=0.005\n",
      ">epoch=933, lrate=1.000, error=0.005\n",
      ">epoch=934, lrate=1.000, error=0.005\n",
      ">epoch=935, lrate=1.000, error=0.005\n",
      ">epoch=936, lrate=1.000, error=0.005\n",
      ">epoch=937, lrate=1.000, error=0.005\n",
      ">epoch=938, lrate=1.000, error=0.005\n",
      ">epoch=939, lrate=1.000, error=0.005\n",
      ">epoch=940, lrate=1.000, error=0.005\n",
      ">epoch=941, lrate=1.000, error=0.005\n",
      ">epoch=942, lrate=1.000, error=0.005\n",
      ">epoch=943, lrate=1.000, error=0.005\n",
      ">epoch=944, lrate=1.000, error=0.005\n",
      ">epoch=945, lrate=1.000, error=0.005\n",
      ">epoch=946, lrate=1.000, error=0.005\n",
      ">epoch=947, lrate=1.000, error=0.005\n",
      ">epoch=948, lrate=1.000, error=0.005\n",
      ">epoch=949, lrate=1.000, error=0.005\n",
      ">epoch=950, lrate=1.000, error=0.005\n",
      ">epoch=951, lrate=1.000, error=0.005\n",
      ">epoch=952, lrate=1.000, error=0.005\n",
      ">epoch=953, lrate=1.000, error=0.005\n",
      ">epoch=954, lrate=1.000, error=0.005\n",
      ">epoch=955, lrate=1.000, error=0.005\n",
      ">epoch=956, lrate=1.000, error=0.005\n",
      ">epoch=957, lrate=1.000, error=0.005\n",
      ">epoch=958, lrate=1.000, error=0.005\n",
      ">epoch=959, lrate=1.000, error=0.005\n",
      ">epoch=960, lrate=1.000, error=0.005\n",
      ">epoch=961, lrate=1.000, error=0.005\n",
      ">epoch=962, lrate=1.000, error=0.005\n",
      ">epoch=963, lrate=1.000, error=0.005\n",
      ">epoch=964, lrate=1.000, error=0.005\n",
      ">epoch=965, lrate=1.000, error=0.005\n",
      ">epoch=966, lrate=1.000, error=0.005\n",
      ">epoch=967, lrate=1.000, error=0.005\n",
      ">epoch=968, lrate=1.000, error=0.005\n",
      ">epoch=969, lrate=1.000, error=0.005\n",
      ">epoch=970, lrate=1.000, error=0.005\n",
      ">epoch=971, lrate=1.000, error=0.005\n",
      ">epoch=972, lrate=1.000, error=0.005\n",
      ">epoch=973, lrate=1.000, error=0.005\n",
      ">epoch=974, lrate=1.000, error=0.005\n",
      ">epoch=975, lrate=1.000, error=0.005\n",
      ">epoch=976, lrate=1.000, error=0.005\n",
      ">epoch=977, lrate=1.000, error=0.005\n",
      ">epoch=978, lrate=1.000, error=0.005\n",
      ">epoch=979, lrate=1.000, error=0.005\n",
      ">epoch=980, lrate=1.000, error=0.005\n",
      ">epoch=981, lrate=1.000, error=0.005\n",
      ">epoch=982, lrate=1.000, error=0.005\n",
      ">epoch=983, lrate=1.000, error=0.005\n",
      ">epoch=984, lrate=1.000, error=0.005\n",
      ">epoch=985, lrate=1.000, error=0.005\n",
      ">epoch=986, lrate=1.000, error=0.005\n",
      ">epoch=987, lrate=1.000, error=0.005\n",
      ">epoch=988, lrate=1.000, error=0.005\n",
      ">epoch=989, lrate=1.000, error=0.005\n",
      ">epoch=990, lrate=1.000, error=0.005\n",
      ">epoch=991, lrate=1.000, error=0.005\n",
      ">epoch=992, lrate=1.000, error=0.005\n",
      ">epoch=993, lrate=1.000, error=0.005\n",
      ">epoch=994, lrate=1.000, error=0.005\n",
      ">epoch=995, lrate=1.000, error=0.005\n",
      ">epoch=996, lrate=1.000, error=0.005\n",
      ">epoch=997, lrate=1.000, error=0.005\n",
      ">epoch=998, lrate=1.000, error=0.005\n",
      ">epoch=999, lrate=1.000, error=0.005\n",
      "[{'weights': [1.3334610117002106, 0.80917951597068, 0.8102576447449061], 'output': 0.9999990643000904, 'delta': -8.486019842246916e-10}, {'weights': [2.5651674647078955, -4.035903584500035, -0.8272658223717634], 'output': 0.9909373603667286, 'delta': 3.45122823718331e-05}]\n",
      "[{'weights': [2.257630748020625, -8.410378564442574, 1.906725832293663], 'output': 0.015230273584542674, 'delta': -0.0002284284004134143}, {'weights': [-1.7106372012268205, 8.40633030321677, -2.450162335010934], 'output': 0.984762890956722, 'delta': 0.00022863190013066792}]\n"
     ]
    }
   ],
   "source": [
    "n_inputs = len(dataset[0]) - 1# 뉴럴렛의 입력노드로 뭐가 들어가죠? 그럼 입력 노드의 개수는?\n",
    "#데이터셋에 들어있는 개수는 끝에 output label값도 포함하고 있으므로 그건 빼고!\n",
    "n_outputs = len(set([row[-1] for row in dataset])) # 뉴럴렛의 출력노드의 개수는 뭐라고 했죠? \n",
    "#데이터셋의 맨마지막 부분 label값이 몇가지인지 그걸 set집합으로 중복된거 제거해서 그 개수를 세어준다\n",
    "#여기서는 0 1 두가지 이므로 2개\n",
    "network = initialize_network(n_inputs, 2, n_outputs) #먼저 네트워크 초기 설정\n",
    "\n",
    "for layer in network:\n",
    "    print(layer) # 초기 네트워크 \n",
    "#학습된 네트워크랑 초기 네트워크를 비교하기 위해 먼저 초기 네트워크 출력했습니다\n",
    "\n",
    "\n",
    "train_network(network, dataset, 1.0, 1000, n_outputs) # 자유롭게 설정하고 최적을 찾아보세요.\n",
    "\n",
    "\n",
    "\n",
    "# 학습된(최적화)된 네트워크가 초기 네트워크와 달리 어떻게 변하였는지 출력하시별로,hint : for문))\n",
    "for layer in network:\n",
    "    print(layer) # 학습된(최적화된) 네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 네트워크로 예측값을 뽑아보자.\n",
    "\n",
    "def predict(network, row):\n",
    "    outputs = forward_propagate(network, row)\n",
    "    return outputs.index(max(outputs)) # 순전파 결과에서 어떤것이 최종 아웃풋이 되나요?\n",
    "    #output값으로 나온 두 값중 더 큰 값의 index값을 최종 아웃풋으로 된다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19890425627850458, 0.7877146498611793]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(network,row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제값=0, 예측값=0\n",
      "실제값=0, 예측값=0\n",
      "실제값=0, 예측값=0\n",
      "실제값=0, 예측값=0\n",
      "실제값=0, 예측값=0\n",
      "실제값=1, 예측값=1\n",
      "실제값=1, 예측값=1\n",
      "실제값=1, 예측값=1\n",
      "실제값=1, 예측값=1\n",
      "실제값=1, 예측값=1\n"
     ]
    }
   ],
   "source": [
    "# 네트워크가 잘 학습되었는지 확인해보자. \n",
    "\n",
    "for row in dataset:\n",
    "    prediction = predict(network,row) # 앞서 최적(학습)시킨 네트워크로 잘 학습되었는지 평가 \n",
    "    print('실제값=%d, 예측값=%d' % (row[-1], prediction)) #아주 잘 학습되었음!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
